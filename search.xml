<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Notes for Stanford CS229 course</title>
      <link href="/2022/04/06/Notes-for-Stanford-CS229-course/"/>
      <url>/2022/04/06/Notes-for-Stanford-CS229-course/</url>
      
        <content type="html"><![CDATA[<h1 id="course-description">Course Description</h1><p>This course provides a broad introduction to machine learning andstatistical pattern recognition. Topics include: supervised learning(generative/discriminative learning, parametric/non-parametric learning,neural networks, support vector machines); unsupervised learning(clustering, dimensionality reduction, kernel methods); learning theory(bias/variance tradeoffs, practical advice); reinforcement learning andadaptive control. The course will also discuss recent applications ofmachine learning, such as to robotic control, data mining, autonomousnavigation, bioinformatics, speech recognition, and text and web dataprocessing.</p><p><a href="https://www.bilibili.com/video/BV19e411W7ga?spm_id_from=333.788.top_right_bar_window_custom_collection.content.click">[CourseWebsite]</a></p><span id="more"></span><h2 id="l1---introduction">L1 - Introduction</h2><p><strong>Machine Learning definition:</strong> Field of study thatgives computers the ability to learn without being explicitlyprogrammed.</p><h3 id="machine-learning-tool">Machine learning tool</h3><p><strong>Supervised learning</strong>: given a data set (x, y), thegoal is to obtain the mapping of x to y</p><p>​ Regression problem: consistent (output)</p><p>​ Classification problem: discrete (output)</p><p><strong>Unsupervised learning</strong>: just given features but nolabels y</p><p><strong>Deep learning</strong>: part of machine learning</p><p><strong>Machine learning strategy</strong>: systematic engineeringprinciples for machine learning</p><p><strong>Reinforcement learning</strong>: do whatever it wants andjudge it behave good or not (game, robot)</p><h2 id="l2---linear-regression-and-gradient-descent">L2 - LinearRegression and Gradient Descent</h2><p><strong>House price predict</strong>: Training set → learningalgorithm → hypothesis (whose work is getting the area of house andtelling the price of the house)</p><p><strong>Model of linear regression</strong>: <span class="math inline">\(h(x)=\theta_0+\theta_1x_1+\theta_2x_2\)</span></p><p>​ to simplify the formula of hypothesis: <span class="math inline">\(h(x)=\sum_{j=0}^2\theta_jx_j,\ where \ x_0=1\(dummy\ feature)\)</span></p><p>​ and the parameters and feature can be written as: <span class="math inline">\(\Theta=[\theta_0\ \theta_1\ \theta_2]^T\)</span>and <span class="math inline">\(x^{(i)}=[x_0^{(i)}\ x_1^{(i)}\x_2^{(i)}]^T\)</span></p><p>​ <em>Some notation</em>: <span class="math inline">\(\theta\)</span>-''parameters''/weight; ​ <span class="math inline">\(m\)</span>-# training examples (# rows in tableabove); ​ <span class="math inline">\(x\)</span>-"inputs"/features/attributes'; ​ <span class="math inline">\(y\)</span>-"output"/target variable; ​ <span class="math inline">\((x, y)\)</span>-training example; ​ <span class="math inline">\((x^{(i)},y^{(i)})\)</span>-<span class="math inline">\(i^{th}\)</span> training example; ​ <span class="math inline">\(n\)</span>-# features.</p><p><strong>Choose parameters such that <span class="math inline">\(h(x)\approx y\)</span></strong>: to minimize thecost function of: <span class="math display">\[J(\theta)=\frac{1}{2}\sum_{i=1}^m(h_{\theta}(x^{(i)})-y^{(i)})^2\tag{2-1}\]</span> ​ think: why square but not absolute error or errors to thepower of 4</p><p><strong>How to find the minima of cost function</strong>:<em>Gradient descent</em></p><p>​ 1.start with some value of <span class="math inline">\(\theta\)</span> (say <span class="math inline">\(\theta=\vec{0}\)</span>)</p><p>​ 2.keep changing <span class="math inline">\(\theta\)</span> toreduce of <span class="math inline">\(J(\theta)\)</span>: <span class="math inline">\(\theta_j:=\theta_j-\alpha\frac{\partial}{\partial\theta_j}J(\theta)\)</span>,where <span class="math inline">\(\alpha\)</span> is learning rate</p><p>​ it can be derived to <span class="math inline">\(\theta_j:=\theta_j-\alpha\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}\)</span></p><p>​ 3.repeat until convergence</p><p>​ P.S. try learning rate on an exponential scale to obtain thequickest learning rate (doubling or tripling scale)</p><p><strong>Gradient descent algorithm</strong>: another name is "batchgradient descent"</p><p>​ disadvantage: for giant dataset, the "m" will be large, thus the sumwill be very slow, and one step of iteration will cost lots of time.</p><p>​ <em>stochastic gradient descent</em>: instead of scanning allmillion examples. ​ <span class="math inline">\(\theta_j:=\theta_j-\alpha(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}\)</span>(for every j)</p><p><strong>Normal equation</strong>: only can be used in linearregression</p><p>​ solve equation <span class="math inline">\(\nabla_\theta(J(\theta))=0\)</span> to get <span class="math inline">\(\theta\)</span></p><p>​ <em>some notation</em>: <span class="math inline">\(tr\ A\)</span> =sum of $ A_{ii}$; ​ <span class="math inline">\(tr\ A=tr\ A^T\)</span>; ​<span class="math inline">\(\nabla_A(tr\ AB)=B^T\)</span>; ​ <span class="math inline">\(tr\ AB = tr\ BA\)</span>; ​ <span class="math inline">\(tr\ ABC = tr\ CBA\)</span>; ​ <span class="math inline">\(\nabla_A(tr\ AA^TC)=CA+C^TA\)</span>; ​ <span class="math inline">\(\nabla_xb^Tx=b\)</span>; ​ <span class="math inline">\(\nabla_xx^TAx=(A+A^T)x\)</span>.</p><p>​ <em>matrix formula</em>: <span class="math inline">\(X\)</span>-design matrix <span class="math display">\[X=\begin{bmatrix}(x^{(1)})^T \\(x^{(2)})^T \\\vdots\\(x^{(m)})^T\end{bmatrix}\]</span> ​ Thus <span class="math inline">\(J(\theta)=(X\theta-y)^T(X\theta-y)\)</span></p><p>​ and the equation can be simplified into <span class="math inline">\(\frac{1}{2}\nabla_\theta((X\theta-y)^T(X\theta-y))=X^TX\theta-X^Ty=0\)</span></p><p>​ then the <em>normal equation</em> is <span class="math inline">\(X^TX\theta=X^Ty\)</span>, and solve it can get<span class="math inline">\(\theta=(X^TX)^{-1}X^Ty\)</span></p><p>​ if the <span class="math inline">\(X\)</span> is non-invertibleprobably means the same feature repeated twice</p><p><strong>Some theories in exercises</strong>:</p><p>​ <em>Hessian matrix</em>: <span class="math inline">\(\nabla^2f(x)=\frac{\partial }{\partialx^T}(\frac{\partial}{\partial x}f(x))\)</span></p><p>​ <em>Composite function</em>: <span class="math inline">\(\nablag(h(x))=g&#39;(h(x))\nabla h(x),\ where\g:\mathbb{R}\rightarrow\mathbb{R}\ and\h:\mathbb{R}^n\rightarrow\mathbb{R}\)</span></p><p>​ <em>Positive semi-definite(PSD)</em>: if <span class="math inline">\(A=A^T\)</span> and <span class="math inline">\(x^TAx\ge0\)</span> for all <span class="math inline">\(x\ge\mathbb{R}^n\)</span></p><p>​ To judge: A symmetric matrix is PSD if and only if all eigenvaluesare non-negative</p><p>​ <em>Spectral theorem</em>: A matrix <span class="math inline">\(M\)</span> with entries in <span class="math inline">\(\R\)</span> is called <em>symmetric</em> if <span class="math inline">\(M=M^T\)</span>. It states that any symmetricmatrix is diagonalizable.</p><p>​ <em>Eigenvectors and eigenvalues</em>: <span class="math inline">\(A=TDT^{-1}\)</span>, where <span class="math inline">\(D=diag(\lambda_1,...,\lambda_n)\)</span> and <span class="math inline">\(T=[t^{(1)}\cdots t^{(n)}]\)</span>, then <span class="math inline">\(At^{(i)}=\lambda_it^{(i)}\)</span> where <span class="math inline">\(\lambda_i\)</span> is eigenvalues and <span class="math inline">\(t^{(i)}\)</span> is eigenvectors.</p><p>​ <em>Orthogonal</em>: <span class="math inline">\(U^TU=I\)</span>,and <span class="math inline">\(A=UDU^T\)</span>, where <span class="math inline">\(U=[u^{(1)}\cdots u^{(n)}]\)</span>, then <span class="math inline">\(Au^{(i)}=\lambda_iu^{(i)}\)</span></p><h2 id="l3---locally-weighted-logistic-regression">L3 - Locally Weighted&amp; Logistic Regression</h2><p><strong>Locally weighted regression</strong>: non-parametric learningalgorithm, it means amount of parameters need to be keep grow (linearly)with size of data.</p><p>​ Fit <span class="math inline">\(\theta\)</span> to minimize <span class="math inline">\(\sum_{i=1}^m\omega^{(i)}(y^{(i)}-\theta^Tx^{(i)})^2\)</span>,where <span class="math inline">\(\omega^{(i)}\)</span> is a "weighting"function, it can be written as: <span class="math display">\[\omega^{(i)}=exp(\frac{(x^{(i)}-x)^2}{\tau^2})\tag{3-1}\]</span> ​ where <span class="math inline">\(x\)</span> is the locationwhere we want to make prediction, and the shape of this function issimilar as gaussian function, <span class="math inline">\(\tau\)</span>is a hyper-parameter which can decide fatter or narrower curve.</p><p>​ <em>Applications</em>: relatively low dimensional dataset.</p><p><strong>Probabilistic interpretation</strong>: (why leastsquares)</p><p>​ Assume <span class="math inline">\(y^{(i)}=\theta^Tx^{(i)}+\epsilon^{(i)}\)</span>where <span class="math inline">\(\epsilon^{(i)}\)</span> is unmodeledeffects and random noise (<span class="math inline">\(\epsilon^{(i)}\simN(0,\sigma^2)\)</span>);</p><p>​ Assume <span class="math inline">\(\epsilon^{(i)}\)</span> isindependently and identically distributed (IID) <span class="math display">\[(y^{(i)}|x^{(i)};\theta)\sim N(\theta^Tx^{(i)}, \sigma^2)\]</span> ​ where "<span class="math inline">\(;\)</span>" meansparameterized by , <span class="math inline">\(\theta\)</span> is just aset of parameters</p><p>​ the likelihood of <span class="math inline">\(\theta\)</span> is:<span class="math display">\[L(\theta)=p(y|x;\theta)=\prod_{i=1}^mp(y^{(i)}|x^{(i)};\theta)\tag{3-2}\]</span> ​ where <em>likelihood</em> means parameters changed but thedata fixed and <em>probability</em> means parameters fixed but the datachanged.</p><p>​ log likelihood of <span class="math inline">\(\theta\)</span> is:<span class="math display">\[l(\theta)=m\cdotlog\frac{1}{\sqrt{2\pi}\sigma}+\sum_{i=1}^m-\frac{(y^{(i)}-\theta^Tx^{(i)})^2}{2\sigma^2}\tag{3-3}\]</span> ​ eliminate constant, we can get the cost function in linearregression.</p><p>​ <em>notation</em>: MLE - maximum likelihood estimation</p><p><strong>Logistic regression</strong>: <span class="math inline">\(y\in \{0, 1\}\)</span></p><p>​ <em>sigmoid function/ logistic function</em>: <span class="math display">\[g(z)=\frac{1}{1+e^{-z}}\tag{3-4}\]</span> ​ hypothesis: <span class="math display">\[h_\theta(x)=g(\theta^Tx)=\frac{1}{1+e^{-\theta^Tx}}\tag{3-5}\]</span> ​ where <span class="math inline">\(P(y=1|x;\theta)=h_\theta(x)\)</span> and <span class="math inline">\(P(y=0|x;\theta)=1-h_\theta(x)\)</span>, theseprobability can be combined to <span class="math inline">\(P(y|x;\theta)=h(x)^y(1-h(x))^{1-y}\)</span></p><p>​ the log likelihood of <span class="math inline">\(\theta\)</span>:<span class="math display">\[l(\theta)=\sum_{i=1}^my^{(i)}log\ h_\theta(x^{(i)})+(1-y^{(i)})log\(1-h_\theta(x^{(i)}))\tag{3-6}\]</span> ​ batch gradient ascent <span class="math inline">\(\theta_j:=\theta_j+\alpha\frac{\partial}{\partial\theta_j}l(\theta)=\theta_j+\alpha\sum_{i=1}^m(y^{(i)}-h_\theta(x^{(i)}))x_j^{(i)}\)</span>which is as same as the iteration formula in linear regression</p><p><strong>Newton's method</strong>: quadratic convergence <span class="math display">\[\theta^{(t+1)}:=\theta^{(t)}-\frac{l&#39;(\theta^{(t)})}{l&#39;&#39;(\theta^{(t)})}\]</span> ​ if <span class="math inline">\(\theta\)</span> is avector(<span class="math inline">\(\theta\in\mathbb{R}^{n+1}\)</span>),above formula can be written as: <span class="math display">\[\theta^{(t+1)}:=\theta^{(t)}-H^{-1}\nabla_\theta l\tag{3-7}\]</span> ​ where <span class="math inline">\(H\)</span> is Hessianmatrix, <span class="math inline">\(H_{ij}=\frac{\partial^2l}{\partial\theta_i\partial\theta_j}\)</span>(<span class="math inline">\(H\in\mathbb{R}^{(n+1)\times(n+1)}\)</span>).</p><p>​ if # features are too large, gradient descent better, otherwisenewton's method better</p><h2 id="l4---perceptron-generalized-linear-model">L4 - Perceptron &amp;Generalized Linear Model</h2><p><strong>Perceptron Algorithm</strong>: simple and easy to analyze butnot applied in practice</p><p>​ Perceptron has similar function like Sigmoid function: <span class="math display">\[g(z)=\begin{cases}1&amp; z\ge0\\0&amp;z&lt;0\end{cases}\tag{4-1}\]</span> ​ Then the hypothesis can be written as: <span class="math display">\[h_\theta(x)=g(\theta^Tx)\tag{4-2}\]</span> ​ Update rules is as same as above algorithms: <span class="math display">\[\theta_j:=\theta_j+\alpha(y^{(i)}-h_\theta(x^{(i)}))x_j^{(i)}\tag{4-3}\]</span> ​ where <span class="math inline">\(y^{(i)}-h_\theta(x^{(i)})\)</span> will be <span class="math inline">\(1\)</span> when wrong at <span class="math inline">\(y^{(i)}=1\)</span>, <span class="math inline">\(0\)</span> when wrong at <span class="math inline">\(y^{(i)}=0\)</span>, which means if <span class="math inline">\(y=1\)</span>, <span class="math inline">\(\theta\)</span> is closed to x, if <span class="math inline">\(y=0\)</span>, <span class="math inline">\(\theta\)</span> is not closed to x</p><p><strong>Exponential Family</strong>:</p><p>​ PDF (probability mass function): <span class="math display">\[p(y,\eta)=b(y)exp(\eta^TT(y)-a(\eta))\tag{4-4}\]</span></p><p>​ where: ​ <span class="math inline">\(y\)</span> - data; ​ <span class="math inline">\(\eta\)</span> - natural parameter; ​ <span class="math inline">\(T(y)\)</span> - sufficient statistic (<span class="math inline">\(=y\)</span> in this class); ​ <span class="math inline">\(b(y)\)</span> - base measure; ​ <span class="math inline">\(a(\eta)\)</span> - log-partition function(normalizing constant of probability distributions).</p><p>​ <em>Bernoulli</em>: model binary data.</p><p>​ PDF: <span class="math inline">\(\phi\)</span> - probability ofevent <span class="math display">\[p(y,\phi)=\phi^y(1-\phi)^{1-y}\]</span></p><p>​ <em>Gaussian (with fixed variance=1)</em>: <span class="math display">\[p(y;\mu)=\frac{1}{\sqrt{2\pi}}exp(-\frac{(y-\mu)^2}{2})\]</span> ​ <em>Properties of exponential family</em>: ​ a. MLE wrt(withrespect to) <span class="math inline">\(\eta\)</span> is concave andNLL(negative log-likelihood) is convex ​ b. Expectation of y (<span class="math inline">\(E[y; \eta]\)</span>) = <span class="math inline">\(\frac{\partial}{\partial\eta}a(\eta)\)</span> ​ c.<span class="math inline">\(Var[y;\eta]\)</span> = <span class="math inline">\(\frac{\partial^2}{\partial\eta^2}a(\eta)\)</span></p><p>​ <em>Choose model</em>: if <span class="math inline">\(y\)</span> is ​Real - Gaussian; ​ Binary - Bernoulli; ​ Count(non-negative integers) -Poisson; ​ Positive real value integers - Gamma, Exponential; ​Probability distributions - Beta, Dirichlet (Bayesian).</p><p><strong>GLM</strong>:</p><p>​ <em>Assumptions</em>: 1) <span class="math inline">\(y|x;\theta \simExponential\ Family(y)\)</span>; 2) <span class="math inline">\(\eta=\theta^Tx\)</span> <span class="math inline">\(\theta\in\mathbb{R}^n, \ x\in\mathbb{R}^n\)</span>where n is # inputs; 3) Test time: Output <span class="math inline">\(h_\theta(x)=E[y|x;\theta]\)</span></p><p>​ <em>Test time</em>: <span class="math display">\[x\rightarrow\eta=\theta^Tx\rightarrow Exponential\Family(b,a,T)\rightarrow E[y;\eta]=h_\theta(x)\]</span> ​ <em>Train time</em>: <span class="math inline">\(\mathop{max}\limits_\theta\ log\\Pi_{i=1}^mp(y^{(i)},\theta^Tx^{(i)})\)</span>.</p><p>​ <em>Learning Update Rule</em>: <span class="math inline">\(\theta_j:=\theta_j+\sum_{i=1}^m\alpha(y^{(i)}-h_\theta(x^{(i)}))x_J^{(i)}\)</span></p><p>​ <em>Terminology</em>: <span class="math inline">\(\eta\)</span> -natural parameter; ​ <span class="math inline">\(\mu=E[y;\eta]=g(\eta)\)</span> - canonicalresponse function; ​ <span class="math inline">\(\eta=g^{-1}(\mu)\)</span> - canonical linkfunction; ​ <span class="math inline">\(\theta\)</span> - modelparameter; ​ <span class="math inline">\(\phi(Ber),\mu\sigma^2(Gau),\lambda-Poi\)</span> -canonical parameters.</p><p><strong>Softmax Regression</strong>: cross entropy</p><p>​ <em>some notation</em>: <span class="math inline">\(k\)</span> -number of class; ​ <span class="math inline">\(x^{(i)}\in\mathbb{R}^n\)</span>; ​ <span class="math inline">\(Label\ y=\{\{0,1\}^k\}\)</span> eg. <span class="math inline">\(\{0,0,1,0\}\)</span> - one-hot vector, <span class="math inline">\(y\in\mathbb{R}^k\)</span>; ​ <span class="math inline">\(\theta_{class}\in\mathbb{R}^n\)</span>,shape(<span class="math inline">\(k,n\)</span>); ​ <span class="math inline">\(\phi_i\)</span> - probability of <span class="math inline">\(i\)</span> output; ​ <span class="math inline">\(\phi_k=1-\sum_{i=1}^{k-1}\phi_i\)</span> -probability of last output; ​ <span class="math inline">\(T(y)\in\mathbb{R}^{k-1}\)</span>.</p><p>​ <em>Response function</em>: <span class="math display">\[p(y=i|x;\theta)=\phi_i=\frac{e^{\eta_i}}{\sum_{j=1}^k e^{\eta_j}}\]</span> ​ <em>cross Entropy</em>: <span class="math inline">\(-\sum_{y=1}^{k-1}p(y)log\ \hat{p}(y)\)</span>(loss function)</p><h2 id="l5---gda-naive-bayes">L5 - GDA &amp; Naive Bayes</h2><p>​ Above algorithms are called discriminative learning algorithms, inthis class will talk generative learning algorithms.</p><p><em>Discriminative</em>: learn <span class="math inline">\(p(y|x)\)</span> (or <span class="math inline">\(h_\theta(x)=...\)</span> mapping of <span class="math inline">\(x\rightarrow y\)</span>).</p><p><em>Generative</em>: learn <span class="math inline">\(p(x|y)\)</span>, what the feature <span class="math inline">\(x\)</span> given the class <span class="math inline">\(y\)</span>, and learn <span class="math inline">\(p(y)\)</span> which called class prior</p><p><em>Bayes rule</em>: <span class="math display">\[p(y=1|x)=\frac{p(x|y=1)p(y=1)}{p(x)}\]</span> ​ where <span class="math inline">\(p(x)=p(x|y=1)p(y=1)+p(x|y=0)p(y=0)\)</span>.</p><p><strong>Gaussian Discriminant Analysis</strong>: suppose <span class="math inline">\(x\in\mathbb{R}^n\)</span>, drop <span class="math inline">\(x_0=1\)</span> convention</p><p>​ Assume <span class="math inline">\(p(x|y)\)</span> is Gaussian,<span class="math inline">\(z\sim N(\mu,\Sigma)\)</span>, where <span class="math inline">\(z,\mu\in\mathbb{R}^n\)</span> and <span class="math inline">\(\Sigma\in\mathbb{R}^{n\times n}\)</span>. And theexpectation of <span class="math inline">\(z\)</span> (<span class="math inline">\(E[z]\)</span>) = <span class="math inline">\(\mu\)</span>, covariance (<span class="math inline">\(Cov(z)\)</span>) = <span class="math inline">\(E[(z-\mu)(z-\mu)^T]=E[zz^T]-(E[z])^2\)</span> andis symmetric. <span class="math display">\[p(z)=\frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}}exp(-\frac{1}{2}(z-\mu)^T\Sigma^{-1}(z-\mu))\tag{5-1}\]</span> ​ <em>GDA model</em>: <span class="math display">\[p(x|y=0)=\frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}}exp(-\frac{1}{2}(x-\mu_0)^T\Sigma^{-1}(x-\mu_0))\tag{5-2}\]</span></p><p><span class="math display">\[p(x|y=1)=\frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}}exp(-\frac{1}{2}(x-\mu_1)^T\Sigma^{-1}(x-\mu_1))\tag{5-3}\]</span></p><p><span class="math display">\[p(y)=\phi^y(1-\phi)^{1-y}\tag{5-4}\]</span></p><p>​ (<span class="math inline">\(\uparrow\)</span>Thus parameters is<span class="math inline">\(\mu_0,\mu_1\in\mathbb{R}^n,\Sigma\in\mathbb{R}^{n\timesn},\phi\in\R\)</span>)</p><p>​ <em>Learning parameter</em>: Training set - <span class="math inline">\(\{(x^{(i)},y^{(i)})\}_{i=1}^m\)</span></p><p>​ likelihood of parameters: <span class="math inline">\(L(\phi,\mu_0,\mu_1,\Sigma)=\prod_{i=1}^mp(x^{(i)},y^{(i)},\phi,\mu_0,\mu_1,\Sigma)=\prod_{i=1}^mp(x^{(i)}|y^{(i)})p(y^{(i)})\)</span></p><p>​ MLE(maximum likelihood estimation): <span class="math display">\[\mathop{max}\limits_{\phi,\mu_0,\mu_!,\Sigma}\l(\phi,\mu_0,\mu_1,\Sigma)=log\ L(\phi,\mu_0,\mu_1,\Sigma)\]</span> ​ derive it, we can get: <span class="math display">\[\begin{align}\phi&amp;=\frac{\sum_{i=1}^my^{(i)}}{m}=\frac{\sum_{i=1}^{m}1\{y^{(i)}=1\}}{m}\\\mu_0&amp;=\frac{\sum_{i=1}^m1\{y^{(i)}=0\}x^{(i)}}{\sum_{i=1}^m1\{y^{(i)}=0\}}\\\mu_1&amp;=\frac{\sum_{i=1}^m1\{y^{(i)}=1\}x^{(i)}}{\sum_{i=1}^m1\{y^{(i)}=1\}}\\\Sigma&amp;=\frac{1}{m}\sum_{i=1}^m(x^{(i)}-\mu_{y^{(i)}})(x^{(i)}-\mu_{y^{(i)}})^T\end{align}\]</span> ​ where the notation <span class="math inline">\(1\{True\}=1\)</span> is indication operator</p><p>​ <em>Prediction</em>: <span class="math display">\[arg\ \mathop{max}\limits_y\ p(y|x)=arg\ \mathop{max}\limits_y\frac{p(x|y)p(y)}{p(x)}=arg\ \mathop{max}\limits_y\ p(x|y)p(y)\]</span> ​ where the notation <span class="math inline">\(arg\)</span>means get value of <span class="math inline">\(y\)</span> to maximum theformula.</p><p>​ <em>Comparison to logistic regression</em>:</p><p>​ For fixed <span class="math inline">\(\phi,\mu_0,\mu_1,\Sigma\)</span>, plot <span class="math inline">\(p(y=1|x,\phi,\mu_0,\mu_1,\Sigma)\)</span> as afunction of <span class="math inline">\(x\)</span>, then you will findthe curve is exactly Sigmoid function. <span class="math display">\[\begin{cases}x|y=0\sim N(\mu_0,\Sigma)\\x|y=1\sim N(\mu_1,\Sigma)\\y\sim Ber(\phi)\end{cases}\Rightarrow p(y=1|x)=\frac{1}{1+e^{-\theta^Tx}}\]</span> ​ which means the GDA have stronger assumptions, and aboveformula is satisfied for any exponential family distribution. And if thedistribution exactly satisfy above formula, then we can say the GDAdoing better than logistic regression, because the GDA get moreinformation.</p><p>​ If we have lots of data, then we can do less assumption in model,which mean we can choose logistic regression; but GDA compute moreefficiently, and can give better results when dataset satisfy thedistribution approximately.</p><p>​<code>What we give the model is hypothesis and training data</code></p><p><strong>Naive Bayes</strong>: by talking about example of e-mail spamclassification</p><p>​ <em>feature vector x?</em> find the top 10000 occurring words anduse that as a feature set. than turn feature vector <span class="math inline">\(x\)</span> into a binary feature vector. <span class="math inline">\(x\in\{0,1\}^n\)</span>, <span class="math inline">\(x_i=1\)</span><span class="math inline">\(\{\)</span>word <span class="math inline">\(i\)</span> appears in email<span class="math inline">\(\}\)</span></p><p>​ want to model <span class="math inline">\(p(x|y),\ p(y)\)</span>,then we have <span class="math inline">\(2^{10000}\)</span> possiblevalue of <span class="math inline">\(x\)</span> and <span class="math inline">\(2^{10000}\)</span> parameters.</p><p>​ Assume <span class="math inline">\(x_i\ &#39;s\)</span> areconditionally independent given y: (also called Naive Bayes assumption)<span class="math display">\[\begin{align}p(x_1,...,x_{10000}|y)&amp;=p(x_1|y)p(x_2|x_1,y)...p(x_{10000}|...)\\&amp;\overset{assume}{=}p(x_1|y)p(x_2|y)...p(x_{10000}|y)\end{align}\]</span> ​ <em>parameters</em>: ​ <span class="math inline">\(\phi_{j|y=1}=p(x_j=1|y=1)\)</span> ​ <span class="math inline">\(\phi_{j|y=0}=p(x_j=1|y=0)\)</span> ​ <span class="math inline">\(\phi_y=p(y=1)\)</span></p><p>​ <em>Joint likelihood</em>: <span class="math display">\[L(\phi_y,\phi_{j|y})=\prod_{i=1}^mp(x^{(i)},y^{(i)};\phi_y,\phi_{j|y})\]</span> ​ <em>MLE</em>: <span class="math display">\[\phi_y=\frac{\sum_{i=1}^m1\{y^{(i)}=1\}}{m}\\\phi_{j|y=1}=\frac{\sum_{i=1}^m1\{x_j^{(i)}=1,y^{(i)}=1\}}{\sum_{i=1}^m1\{y^{(i)}=1\}}\]</span></p><h2 id="l6---support-vector-machines">L6 - Support Vector Machines</h2><p><strong>Naive theory limitations</strong>:</p><p>​ at prediction time: <span class="math display">\[p(y=1|x)=\frac{p(x|y=1)p(y=1)}{p(x)}\]</span> ​ if there is a word doesn't exist in the training set, thenwhen it first comes out, the model will treat its probability as zero(<span class="math inline">\(p(x_k|y)=0\)</span>), than the formulaabove will become <span class="math inline">\(0/(0+0)\)</span>.</p><p><strong>Laplace smoothing</strong>:</p><p>​ set <span class="math inline">\(x\in\{1,...,k\}\)</span>, estimateof <span class="math inline">\(x=j\)</span> : <span class="math display">\[p(x=j)=\frac{\sum_{j=1}^m1\{x^{(i)}=j\}+1}{m+k}\tag{6-1}\]</span> ​ it says the numerator plus one, and denominator plus thenumber of <span class="math inline">\(x\)</span>.</p><p><strong>Two models</strong>:</p><p>​ for e-mail spam, there are two models to describe features <span class="math inline">\(x\)</span>:</p><p>​ <em>Multivariate Bernoulli Model</em>: <span class="math inline">\(x\in\mathbb{R}^n\)</span>, where n is the numberof words in dictionary. so if a e-main is received, it can be written as<span class="math inline">\(x=[0\ 0\  ...\ 1\ ...\ 0]\)</span></p><p>​ <em>Multinomial Event Model</em>: <span class="math inline">\(x\in\mathbb{R}^n\)</span>, where n is the lengthof e-mail, then <span class="math inline">\(x=[1600\ 800\ 1600\800]\)</span></p><p>​ probability: <span class="math inline">\(p(x,y)=p(x|y)p(y)\overset{assume}{=}\prod_{j=1}^np(x_j|y)...p(y)\)</span></p><p>​ parameters: <span class="math inline">\(\phi_y=p(y=1)\)</span>,<span class="math inline">\(\phi_{k|y=0}=p(x_j=k|y=0)\)</span></p><p>​ MLE: <span class="math display">\[\phi_{k|y=0}=\frac{\sum_{i=1}^m1\{y^{(i)}=0\}\sum_{j=1}^{n_i}1\{x_j^{(i)}=k\}+1}{\sum_{i=1}^m1\{y^{(i)}=0\}n_i+|V|}\]</span> ​ where <span class="math inline">\(|V|\)</span> is the numberof possible values of <span class="math inline">\(x\)</span>.</p><p>​<code>Start ML: collect dataset and build a simple algorithm then see what it's doing wrong and improve it</code></p><p><strong>Support vector machine</strong>:</p><p>​ <em>geometric margin</em>: the distance between training example todecision boundary. <span class="math display">\[\gamma^{(i)}=\frac{\omega^Tx^{(i)}+b}{||\omega||}\]</span> ​ <span class="math inline">\(\gamma=\mathop{min}\limits_i\\gamma^{(i)},\ where \ i=1,...,m\)</span></p><p>​ <em>notation</em>: ​ labels <span class="math inline">\(y\in\{-1,+1\}\)</span>; ​ have <span class="math inline">\(h\)</span> output values in <span class="math inline">\(\{-1,+1\}\)</span>; ​ <span class="math inline">\(g(z)=\begin{cases}1\ \ \  \ z\ge0\\-1\othersise\end{cases}\)</span></p><p>​ <em>hypothesis of SVM</em>: <span class="math display">\[h_{\omega,b}=g(\omega^Tx+b), where\ \omega\in\R^n\ and\ b\in\R\]</span> ​ <em>functional margin of (<span class="math inline">\(\omega,b\)</span>)</em>: <span class="math inline">\(\hat\gamma^{(i)}=y^{(i)}(\omega^Tx^{(i)}+b)\)</span>,and we want <span class="math inline">\(\hat\gamma^{(i)}\gg1\)</span>.for whole training set <span class="math inline">\(\hat\gamma=\mathop{min}\limits_i\\hat\gamma^{(i)},\ where \ i=1,...,m\)</span></p><p>​ we can cheat by times 10 to parameters, then we have 10 timesfunctional margin, in order to avoid this cheating way: <span class="math inline">\((\omega,b)\rightarrow(\frac{\omega}{||\omega||},\frac{b}{||\omega||})\)</span>.so we have geometric margin <span class="math inline">\(\gamma^{(i)}=\hat\gamma^{(i)}/||\omega||\)</span></p><p>​ <em>optimal margin classifier</em>: basic building block in SVM</p><p>​ <span class="math inline">\(h_\theta(x)=g(\theta^Tx)\)</span>,predict "<span class="math inline">\(1\)</span>" if <span class="math inline">\(\theta^Tx\ge0\)</span>, "<span class="math inline">\(0\)</span>" otherwise. which means if <span class="math inline">\(y^{(i)}=1\)</span> hope that <span class="math inline">\(\theta^Tx\gg0\)</span> and if <span class="math inline">\(y^{(i)}=0\)</span> hope that <span class="math inline">\(\theta^Tx\ll0\)</span>.</p><p>​ parameter: choose <span class="math inline">\(\omega,b\)</span> tomaximize <span class="math inline">\(\gamma\)</span>, it can be provedthat it's same to: (s.t. means subject to) <span class="math display">\[\mathop{min}\limits_{\omega,b}\ \frac{1}{2}||\omega||^2,\ s.t.\y^{(i)}(\omega^Tx^{(i)}+b)\ge1,\ i=1,...,n\]</span></p><h2 id="l7---kernels">L7 - Kernels</h2><p>To solve when features x is 100 trillion dimensional</p><p><strong>Intuition</strong>:</p><ol type="1"><li><p><span class="math inline">\(\omega=\sum_{i=1}^m\alpha_ix^{(i)}\)</span>, whichcan be proved true; (and we can prove by induction from Eq.4-3)</p></li><li><p>vector <span class="math inline">\(omega\)</span> isperpendicular to decision boundary(<span class="math inline">\(omega\)</span> controls direction ofboundary);</p><p>Let <span class="math inline">\(\omega=\sum_{i=1}^m\alpha_iy^{(i)}x^{(i)}\)</span>,then the optimization objective can be written as:</p></li></ol><p><span class="math display">\[\frac{1}{2}\sum_i\sum_j\alpha_i\alpha_jy^{(i)}y^{(j)}&lt;x^{(i)},x^{(j)}&gt;\]</span></p><p>​ where <span class="math inline">\(&lt;x,z&gt;=x^Tz\)</span> is theinner product</p><p>​ And s.t. becomes: <span class="math display">\[y^{(i)}(\sum_{ij}\alpha_jy^{(j)}&lt;x^{(j)},x^{(j)}&gt;+b)\ge1\]</span> <strong>kernel trick</strong>:</p><ol type="1"><li>write algorithm in terms of <span class="math inline">\(&lt;x^{(i)},x^{(j)}&gt;\)</span>; (sometimes itcan be written as <span class="math inline">\(&lt;x,z&gt;\)</span>)</li><li>let that be mapping from <span class="math inline">\(x\)</span> to<span class="math inline">\(\phi(x)\)</span> (it would be <span class="math inline">\([x\ x^2\ x^3...]\)</span> or <span class="math inline">\([x_1\ x_2\ x_1x_2\ ...]\)</span>, it can beinfinite dimensional);</li><li>find the way to compute <span class="math inline">\(K(x,z)=\phi(x)^T\phi(z)\)</span> (it's calledkernel function);</li><li>replace <span class="math inline">\(&lt;x,z&gt;\)</span> by <span class="math inline">\(K(x,z)\)</span></li></ol><p><strong>Example</strong>:</p><p>​ -suppose we have features <span class="math inline">\(x\in\mathbb{R}^n\)</span> and <span class="math inline">\(\phi(x)\in\mathbb{R}^{n^2}\)</span>, it means ifwe want to calculate <span class="math inline">\(K(x,z)\)</span> thereneed to take <span class="math inline">\(O(n^2)\)</span> time. (<span class="math inline">\(\phi(x)=[x_ix_j\ for\ i,j=1,2...]\)</span>), itcan be proved that: <span class="math display">\[K(x,z)=\phi(x)^T\phi(z)=(x^Tz)^2\]</span> ​ which take <span class="math inline">\(O(n)\)</span> time</p><p>​ -if we append <span class="math inline">\(\phi(x)\)</span> by <span class="math inline">\([\sqrt{2c}x_i\ i=1,2,...]\cup[c]\)</span> then<span class="math inline">\(K(x,z)=(x^Tz+c)^2\)</span></p><p>​ -if <span class="math inline">\(K(x,z)=(x^Tz+c)^d\)</span> then<span class="math inline">\(\phi(x)\)</span> has all features ofmonomial up to order <span class="math inline">\(d\)</span></p><p><code>Optimal margin classifier + kernal trick = SVM</code></p><p>So what <em>SVM</em> is doing is <em>mapping feature</em> to muchhigher dimensional feature space, and use a <em>hyperplane</em> to bedecision boundary, then <em>project it</em> back down to the originalfeature space, it will end up with <em>a very non-linear decisionboundary</em>.</p><p><strong>How to make kernels</strong>:</p><p>​ If <span class="math inline">\(x,z\)</span> are similar, the kernelfunction is large; if <span class="math inline">\(x,z\)</span> are notsimilar, the kernel function is small. (just like the inner product ofvector, if two vector are similar, then the product will be large)</p><p>​ <span class="math inline">\(K(x,z)=exp(-\frac{||x-z||^2}{2\sigma^2})\)</span>is kernel function? yes, gaussian kernel</p><ul><li><p>does that exist <span class="math inline">\(\phi\)</span> s.t.<span class="math inline">\(K(x,z)=\phi(x)^T\phi(z)\)</span>;</p></li><li><p><span class="math inline">\(K(x,x)=\phi(x)^T\phi(x)\ge0\)</span></p></li><li><p>Let <span class="math inline">\(\{x^{(1)},...,x^{(d)}\}\)</span>be <span class="math inline">\(d\)</span> points, let <span class="math inline">\(K\in\mathbb{R}^{d\times d}\)</span> called 'kernelmatrix' <span class="math inline">\(K_{ij}=K(x^{(i)},x^{(j)})\)</span>,<span class="math inline">\(K\)</span> is positivesemi-definite</p></li><li><p>Mercer theorem: <span class="math inline">\(K\)</span> is a validkernel function if and only if for any d points <span class="math inline">\(\{x^{(1)},...,x^{(d)}\}\)</span>, thecorresponding kernel matrix <span class="math inline">\(K\)</span> is apositive semi-definite.</p><p><em>most used</em>: Linear kernel function: <span class="math inline">\(K(x,z)=x^Tz\)</span> and <span class="math inline">\(\phi(x)=x\)</span></p><p><em>second used</em>: Gaussian kernel function. <span class="math inline">\(\phi(x)\in\mathbb{R}^\infty\)</span></p><p><em>Polynomial kernel</em>: <span class="math inline">\(K(x,z)=(x^Tz)^d\)</span></p></li></ul><p><strong>L1 norm soft margin SVM</strong>: <span class="math display">\[\begin{align}&amp;\mathop{min}\limits_{\omega,b,\xi_i}\\frac{1}{2}||\omega||^2+C\sum_{i=1}^m\xi_i \\&amp;s.t.\ y^{(i)}(\omega^Tx^{(i)}+b)\ge1-\xi_i,\ i=1,...,n\end{align}\]</span> ​ It makes it <em>much more robust</em> outliers.</p><p>​ Bring <span class="math inline">\(\omega=\sum_{i=1}^m\alpha_ix^{(i)}\)</span> intoabove formula then it can be changed to: $$ <span class="math display">\[\begin{align}&amp;\mathop{max}\limits_{\alpha}\sum_{i=1}^n\alpha_i-\frac{1}{2}\sum_i^n\sum_j^ny^{(i)}y^{(j)}\alpha_i\alpha_j&lt;x^{(i)},x^{(j)}&gt;\\&amp;s.t.\ 0\le\alpha_i\le C,\ i=1,...,n;\ \sum_{i=1}^n\alpha_iy^{(i)}=0\end{align}\]</span> $$</p><h2 id="l8---data-splits-models-cross-validation">L8 - Data Splits,Models &amp; Cross-Validation</h2><p><em>underfit - high bias; outfit - high variance</em> (variance meansthat there's a lot of variability in the predictions this algorithm willmake)</p><p><strong>Regularization</strong>: prevent overfitting (it's used veryvery often)</p><p>​ for linear regression: <span class="math display">\[\mathop{min}\limits_\theta\frac{1}{2}\sum_{i=1}^m||y^{(i)}-\theta^Tx^{(i)}||^2+\frac{\lambda}{2}||\theta||^2\]</span> ​ the right side of above formula is called <em>regularizationterm</em>, for the <span class="math inline">\(SVM\)</span> the <span class="math inline">\(\mathop{min}\limits_{\omega,b}\\frac{1}{2}||\omega||^2\)</span> play a similar role as regularizationterm to prevent <span class="math inline">\(SVM\)</span>overfitting.</p><p><strong>Two thoughts</strong> (<span class="math inline">\(s\)</span>is training set)</p><p>​ <em>frequentists</em>: <span class="math inline">\(arg\\mathop{max}\limits_\theta\ p(s|\theta)\)</span> ---- MLE;</p><p>​ <em>Bayesian</em>: prior distribution <span class="math inline">\(p(\theta)\)</span> -&gt; <span class="math inline">\(arg\ \mathop{max}\limits_\theta\p(\theta|s)\)</span> (maximum a posteriori estimation, MAP)</p><p><strong>Dataset in ML</strong>: Train/dev(development)/test sets</p><p>​ -Train each model (option for the degree of polynomial/<span class="math inline">\(\lambda\)</span> for regularization/<span class="math inline">\(C\)</span> for soft margin SVM/<span class="math inline">\(\tau\)</span> for locally weighted regression) ontrain set. Get some hypothesis <span class="math inline">\(h_i\)</span>;</p><p>​ -Measure the error on dev set;</p><p>​ -evaluate algorithm on test set.</p><p><strong>Dataset split</strong>:</p><p><em>Hold-out cross validation</em>:</p><p>​ S -&gt; 70% train, 30% dev ; 60% train, 20% dev, 20% test. It can beused fine when dataset are thousands magnitude or below. (dev set =cross validation set)</p><p>​ choose dev and test sets to be big enough that the difference in theperformance of algorithms can be seen.</p><p><em>k-fold CV</em>: when dataset is small</p><p>​ divide dataset in to <span class="math inline">\(k\)</span> subsets.(<span class="math inline">\(k=10\)</span> is most common choice)</p><p>​ "For model in models: For <span class="math inline">\(i=1,...,k\)</span>: Train on <span class="math inline">\(k-1\)</span> pieces and test on remaining onepiece. Then average error". Choose the model have lowest error, thentrain on the whole dataset.</p><p>​ - advantage: makes more efficient use of the data</p><p>​ - disadvantage: compute very expensive</p><p><em>leave-one-out cross validation</em>: for much smaller dataset(for# examples <span class="math inline">\(&lt;100\)</span>) <span class="math inline">\(k=m\)</span></p><p><strong>Feature selection</strong>: a way to avoid overfitting(special case of model selection)</p><p><em>Forward search</em>:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Starts with f=phi(phi is empty set of features):</span><br><span class="line">Repeat:</span><br><span class="line">1) Try adding each feature i to f. and see which single feature addition most improves the dev set performance</span><br><span class="line">2) Add that feature to f</span><br></pre></td></tr></table></figure><h2 id="l9---approx_estimation-error-erm">L9 - Approx_Estimation Error&amp; ERM</h2><p><strong>Assumptions</strong>:</p><ol type="1"><li>Data distribution D: <span class="math inline">\((x,y)\simD\)</span>, train set and test set are all satisfy thisdistribution;</li><li>All samples are independent;</li><li><span class="math inline">\(\hat{h}\ or\ \hat{\theta}\sim\)</span>sampling distribution, but its true value <span class="math inline">\(h^*\ and\  \theta^*\)</span> are not randomvariable.</li></ol><p><strong>Bias &amp; Variance</strong>: bias is error between estimateparameter and true parameter; and variance is to describe the degree ofdispersion in distribution of estimate parameter.</p><p>​ <em>Statistical efficiency</em>: <span class="math inline">\(m\rightarrow\infty,\Var(\hat\theta)\rightarrow0\)</span>; ​ <em>Consistent</em>: <span class="math inline">\(\hat\theta\rightarrow\theta^*\ as\m\rightarrow\infty\)</span></p><p><strong>Fighting Variance</strong>:</p><pre><code>1) $m\rightarrow\infty$;2) Regularization: get higher bias but lower variance.</code></pre><p><strong>Error about hypothesis</strong>:</p><p>​ <span class="math inline">\(g\)</span> - Best possible hypothesis; ​<span class="math inline">\(h^*\)</span> - Best hypothesis in class<span class="math inline">\(\mathbb{H}\)</span>; ​ <span class="math inline">\(\hat h\)</span> - learnt from finite data ​ <span class="math inline">\(\epsilon(h)\)</span> - Risk / Generalization error= <span class="math inline">\(E_{(x,y)\sim D}[1\{h(x)\ne y\}]\)</span>,infinite process; ​ <span class="math inline">\(\hat\epsilon_s(h)\)</span> - empirical risk =<span class="math inline">\(\frac{1}{m}\sum_{i=1}^m1\{h(x)\ney\}\)</span>, <span class="math inline">\(m\)</span> is finite number; ​<span class="math inline">\(\epsilon(g)\)</span> - Bayes error /irreducible error; ​ <span class="math inline">\(\epsilon(h^*)-\epsilon(g)\)</span> - approximationerror; ​ <span class="math inline">\(\epsilon(\hath)-\epsilon(h^*)\)</span> - estimation error.</p><p>​ <span class="math inline">\(\epsilon(\hat h)\)</span> = estimationerror(by limited data) + approximation error(by model) + irreducibleerror ​ estimation error can be broke down to estimation variance andestimation bias, where estimation variance is what we call<em>variance</em> and estimation variance plus approximation error iswhat we call <em>bias</em>.</p><p><strong>Fight high bias</strong>:</p><p>​ 1) make the space of hypothesis <span class="math inline">\(\mathbb{H}\)</span> bigger, but it increasevariance</p><p><strong>Empirical risk minimization (ERM)</strong>: learningalgorithm <span class="math display">\[\hat h_{ERM}=arg\ \mathop{min}\limits_{h\in\mathbb{H}}\\frac{1}{m}\sum_{i=1}^m1\{h(x^{(i)})\ne y^{(i)}\}\]</span> <strong>Uniform Convergence</strong>: research on <span class="math inline">\(\hat\epsilon(h)\)</span> vs $ (h)$ and <span class="math inline">\(\epsilon(\hat h)\)</span> vs <span class="math inline">\(\epsilon(h^*)\)</span></p><p>​ <em>Tools</em>: ​ 1) Union Bound: ​ For <span class="math inline">\(A_1,A_2,...,A_k\)</span> (could not beindependent), <span class="math inline">\(p(A_1\cup A_2...\cup A_k)\lep(A_1)+p(A_2)+...+p(A_k)\)</span></p><pre><code>    2) Hoeffding&#39;s inequality:</code></pre><p>​ Let <span class="math inline">\(z_1,z_2,...,z_m\sim\)</span>Bern(<span class="math inline">\(\phi\)</span>) (<span class="math inline">\(z_i=\{0,1\}\)</span>), <span class="math inline">\(\hat\phi=\frac{1}{m}\sum_{i=1}^mz_i\)</span> and<span class="math inline">\(\gamma&gt;0\)</span> as a margin.</p><p><span class="math display">\[p[|\hat\phi-\phi|&gt;\gamma]\le 2exp(-2\gamma^2m)\]</span></p><p>​ Apply this two Tools on empirical risk and generalization error:<span class="math inline">\(p(|\hat\epsilon(h)-\epsilon(h)|&gt;\gamma)\le2exp(-2\gamma^2m)\)</span> (which is appliedto one h, next we expand h to H)</p><p>​ <em>For finite hypothesis class</em>:</p><p>​ <span class="math inline">\(\hat\epsilon(h)\)</span> vs $ (h)$:<span class="math inline">\(|\mathbb{H}|=k\)</span> <span class="math display">\[p(\forallh\in\mathbb{H},|\hat\epsilon(h)-\epsilon(h)|&lt;\gamma)\ge1-2k\exp(-2\gamma^2m)\]</span> ​ Let <span class="math inline">\(\delta=2k\exp(-2\gamma^2m)\)</span> - probabilityof error; <span class="math inline">\(\gamma\)</span> - margin error;<span class="math inline">\(m\)</span> - sample size <span class="math display">\[m\ge\frac{1}{2\gamma^2}\log\frac{2k}{\delta}\]</span> ​ (it has another name "sample complexity")</p><p>​ <span class="math inline">\(\epsilon(\hat h)\)</span> vs <span class="math inline">\(\epsilon(h^*)\)</span>: <span class="math display">\[\begin{align}\epsilon(\hat h)&amp;\le\hat\epsilon(\hat h)+\gamma\\&amp;\le\hat\epsilon(h^*)+\gamma\ (because\ \hat h\ is\ best\estimation\ error\ in\ \mathbb{H})\\&amp;\le\epsilon(h^*)+2\gamma\\&amp;\le\epsilon(h^*)+2\sqrt{\frac{1}{2m}\log\frac{2k}{\delta}}\end{align}\]</span> <strong>VC dimension</strong></p><p><em>Shatter</em>: 当假设空间 <span class="math inline">\(\mathcal{H}\)</span> 作用于大小为 <span class="math inline">\(N\)</span> 的样本集 <span class="math inline">\(\mathcal{D}\)</span> 时, 产生的对分数量等于 <span class="math inline">\(2^{N}\)</span> 即 <span class="math inline">\(m_{\mathcal{H}}(N)=2^{N}\)</span> 时, 就称 <span class="math inline">\(\mathcal{D}\)</span> 被 <span class="math inline">\(\mathcal{H}\)</span> 打散了。</p><p><em>VC dimension</em>: at least <span class="math inline">\(d\)</span> <span class="math display">\[|\varepsilon(h)-\hat{\varepsilon}(h)| \leq O\left(\sqrt{\frac{d}{m} \log\frac{m}{d}+\frac{1}{m} \log \frac{1}{\delta}}\right)\]</span></p><p><span class="math display">\[\varepsilon(\hat{h}) \leq\varepsilon\left(h^{*}\right)+O\left(\sqrt{\frac{d}{m} \log\frac{m}{d}+\frac{1}{m} \log \frac{1}{\delta}}\right)\]</span></p><p>The number of training examples needed is usually roughly linear inthe number of parameters of <span class="math inline">\(\H\)</span>.</p><h2 id="l10---decision-trees-ensemble-methods">L10 - Decision Trees&amp; Ensemble Methods</h2><p><strong>Decision Trees</strong>: Greedy, Top-Down, Recursive,Partitioning, fairly high variance models</p><p><span class="math display">\[S_p(j, t)=(\{X|X_j&lt;t,X\in R_p\},\{X|X_j\ge t,X\in R_p\})\]</span> ​ where: ​ <span class="math inline">\(R_p\)</span> - Region ofparents; ​ <span class="math inline">\(S_p\)</span> - Looking for asplit, it gives two outputs, <span class="math inline">\(R_1,R_2\)</span>; ​ <span class="math inline">\(t\)</span> - threshold; ​ <span class="math inline">\(j\)</span> - feature number.</p><p>​ <em>How to choose splits</em>:</p><p>​ Define <span class="math inline">\(L(R)\)</span>: loss on R ​ Given<span class="math inline">\(C\)</span> classes, define <span class="math inline">\(\hat p_c\)</span> to be proportion of examples inR that are of class <span class="math inline">\(C\)</span>. <span class="math display">\[L_{misclassification}=1-\mathop {max}\limits_c \hat p_c\]</span> ​ The goal is to maximize <span class="math inline">\(L(R_p)-(L(R_1)+L(R_2))\)</span> with parameters<span class="math inline">\(j,t\)</span>. Actually <span class="math inline">\(L(R_p)\)</span> is constant, thus what we want todo is to minimize the loss of children.</p><p>​ However this misclassification have issues that it would not makeclassier working better if two child have same amounts. Instead definecross entropy loss: <span class="math display">\[L_{cross}=-\sum_c\hat p_c\log_2\hat p_c\]</span> <img src="/2022/04/06/Notes-for-Stanford-CS229-course/image-20210307200624480.png" alt="image-20210307200624480"></p><p>the shape of Gini loss is similar as cross-entropy: <span class="math inline">\(\sum_c \hat p_c(1-\hat p_c)\)</span></p><p>​ <em>Regression Trees</em>:</p><p>​ Predict <span class="math inline">\(\hat y_m=\sum_{i\inR_m}y_i/|R_m|\)</span> <span class="math display">\[L_{squared}=\frac{\sum_{i\in R_m}(y_i-\hat y_m)^2}{|R_m|}\]</span> ​ <em>Regularization of DTs</em>:</p><p>​ 1) min leaf size; ​ 2) max depth; ​ 3) max number of nodes; ​ 4) mindecrease in loss; ​ 5) pruning (misclassification with validationset).</p><p>​ <em>Runtime</em>:</p><p>​ some notation: <span class="math inline">\(n\)</span>-examples;<span class="math inline">\(f\)</span>-features; <span class="math inline">\(d\)</span>-depth. <span class="math inline">\(d&lt;\log_2n\)</span>. Each point is part of <span class="math inline">\(O(d)\)</span> nodes, cost of point at each node is<span class="math inline">\(O(f)\)</span>, So total cost is <span class="math inline">\(O(nfd)\)</span>.</p><p>​ <em>No additive structure</em>: when the features are interactingadditively with one_another</p><p>​ <em>Recap</em>: ​ advantage: Easy to explain; Interpretable;Categorical Variables ​ disadvantage: High variance; Bad at additive; lowpredictive accuracy</p><p><strong>Ensemble</strong>: If <span class="math inline">\(X_i&#39;s\)</span> are ID(identical distribution),and <span class="math inline">\(X_i\)</span> is correlated by <span class="math inline">\(\rho\)</span> <span class="math display">\[Var(\bar x)=\rho\sigma^2+\frac{1-\rho}{n}\sigma^2\]</span> ​ <em>Ways to ensemble</em>: 1) different algorithms; 2)different training sets; 3) Bagging (Random Forest); 4) Boosting(Adaboost, xgboost).</p><p>​ <em>Bagging - Bootstrap Aggregation</em>:</p><p>​ Bootstrap: the method used in statistics to measure uncertainty yourestimate</p><p>​ Have a true population <span class="math inline">\(P\)</span>,training set <span class="math inline">\(S\)</span> sampled from <span class="math inline">\(P\)</span>. Assume <span class="math inline">\(P=S\)</span>, bootstrap samples <span class="math inline">\(Z\)</span> sampled from <span class="math inline">\(S\)</span> (<span class="math inline">\(z_1,...,z_M\)</span>). Then train model <span class="math inline">\(G_m\)</span> on <span class="math inline">\(z_m\)</span>, we can get <span class="math inline">\(G(m)=\sum_{i=1}^M G_m(x)/M\)</span>. Bootstrappingis driving down <span class="math inline">\(\rho\)</span>, so variancewill decrease, however, because shape(<span class="math inline">\(Z\)</span>) is smaller than shape(<span class="math inline">\(S\)</span>), so bias will slightly increased.</p><p>​ - Random Forests: At each split, consider only a fraction of totalfeatures, it would decrease <span class="math inline">\(\rho\)</span>and decorrelate models</p><p>​ <em>Boosting</em>(Adaboost) : decreasing bias of model. Determinefor classifier <span class="math inline">\(G_m\)</span> a weight <span class="math inline">\(\alpha_m\)</span> proportional <span class="math inline">\(\log(1-err_m/err_m)\)</span>, <span class="math inline">\(G(x)=\sum_m\alpha_mG_m\)</span> and each <span class="math inline">\(G_m\)</span> is trained on a reweighted trainingset.</p><h2 id="l11---introduction-to-neural-networks">L11 - Introduction toNeural Networks</h2><p><strong>Deep Learning</strong>:</p><ul><li>computational power (GPU)</li><li>data available (more data can get more salient feature)</li><li>algorithms</li></ul><p><strong>Logistic Regression</strong>: Goal find cats in images (1<span class="math inline">\(\rightarrow\)</span> presence of a cat; 0<span class="math inline">\(\rightarrow\)</span> absence of a cat)</p><p>​ colored picture (size <span class="math inline">\(64\times64\)</span>) <span class="math inline">\(\rightarrow\)</span> length <span class="math inline">\(64\times64\times3\)</span> vector (where <span class="math inline">\(3\)</span> represent RGB) <span class="math inline">\(\rightarrow\)</span> <span class="math inline">\(h=wx+b\)</span> <span class="math inline">\(\rightarrow\)</span> <span class="math inline">\(g(h)=sigmoid(h)\)</span> <span class="math inline">\(\rightarrow\)</span> <span class="math inline">\(\hat y=\sigma(\theta^Tx)\)</span> (where <span class="math inline">\(x\)</span>=shape(64*64*3, 1) and <span class="math inline">\(w\)</span>=shape(1, 64*64*3))</p><p>​ 1) initiate <span class="math inline">\(w,b\)</span> ; ​ 2) find theoptimal <span class="math inline">\(w\)</span> and <span class="math inline">\(b\)</span>; (<span class="math inline">\(L=-[y\log\hat y+(1-y)\log(1-\hat y)]\)</span> anduse gradient descent method to update parameters) ​ 3) use <span class="math inline">\(\hat y=\sigma(wx+b)\)</span> to predict</p><p>​ <em>Goal2.0</em>: find cat/lion/iguana in images</p><p>​ (Eq1) neural = linear + activation ​ (Eq2) model = architecture +parameters</p><p>​ In order to classify these three animals, we need three output nodesnamed by <span class="math inline">\(a_1^{[1]},a_2^{[1]},a_3^{[1]}\)</span> wheresquare brackets represent the index of the layer. However it will doworse when there are rare iguanas, so the <span class="math inline">\(a^{[1]}_3\)</span> will be rarely trained, and themodel ignore the correlation between animals.</p><p>​ <em>Goal3.0</em>: + constraint which is an unique animal on animage. (Let's call <span class="math inline">\(w^{[1]}_1x+b_1^{[1]}\)</span> as <span class="math inline">\(z_1^{[1]}\)</span>)</p><p>​ Using softmax multi-class network to replace simoid function, (e.g.<span class="math inline">\(e^{z_3^{[1]}}/\sum_{k=1}^3e^{z_k^{[1]}}\)</span>),loss function will be <span class="math inline">\(-\sum_{k=1}^{3}p(y)log\ \hat{p}(y)\)</span></p><p>​ If we want to predict the cats' age, we can replace simoid functionby ReLU function, the ReLU function is <span class="math inline">\(f(x)=\max(0,x)\)</span> (ReLU - rectified linearunits)</p><p><strong>Neural Networks</strong>: end to end learning / black boxmodel</p><p>​ <em>Propagation equation</em>: (the architect of network is [3, 2,1]) ​ Input matrix: <span class="math inline">\(X-shape(m,n)\)</span>,<span class="math inline">\(x^{(1)}-shape(1,n)\)</span> as a singleexample <span class="math display">\[X=(x^{(1)}\cdots x^{(m)})^T\]</span> ​ The first layer: <span class="math inline">\(w^{[1]}-shape(n,3),Z^{[1]}-shape(m,3),b^{[1]}-shape(1,3)\)</span>where <span class="math inline">\(b^{[1]}\)</span> will be broadcastedby numPy automatically to <span class="math inline">\(shape(m,3)\)</span> <span class="math display">\[\begin{align}&amp;Z^{[1]}=Xw^{[1]}+b^{[1]}\\&amp;a^{[1]}=\sigma(z^{[1]})\end{align}\]</span> ​ The second layer: <span class="math inline">\(w^{[2]}-shape(3,2),Z^{[2]}-shape(m,2),b^{[2]}-shape(1,2)\)</span><span class="math display">\[\begin{align}&amp;Z^{[2]}=a^{[1]}w^{[2]}+b^{[2]}\\&amp;a^{[2]}=\sigma(z^{[2]})\end{align}\]</span> ​ The second layer: <span class="math inline">\(w^{[3]}-shape(2,1),Z^{[3]}-shape(m,1),b^{[2]}-shape(1,1)\)</span><span class="math display">\[\begin{align}&amp;Z^{[3]}=a^{[2]}w^{[3]}+b^{[3]}\\&amp;\hat y=a^{[3]}=\sigma(z^{[3]})\end{align}\]</span> ​ <em>Optimizing all the parameters</em>:</p><p>​ Define loss function (1 example) or cost function (multipleexamples): <span class="math display">\[J(\hat y,y)=\frac{1}{m}\sum_{i=1}^mL^{(i)}\\with\ L^{(i)}=-[y^{(i)}\log\hat y^{(i)}+(1-y^{(i)})\log(1-\hat y^{(i)})]\]</span> ​ <em>Backward propagation</em>: <span class="math display">\[\begin{align}\forall l=1,2,3\qquad w^{[l]}&amp;=w^{[l]}-\alpha\frac{\partialJ}{\partial w^{[l]}}\\b^{[l]}&amp;=b^{[l]}-\alpha\frac{\partial J}{\partial b^{[l]}}\end{align}\]</span></p><h2 id="l12---backprop-improving-neural-networks">L12 - Backprop &amp;Improving neural networks</h2><p><strong>backpropagation</strong>: (shape of <span class="math inline">\(X\)</span> is <span class="math inline">\((n,m)\)</span>) <span class="math display">\[\frac{\partial L^{(i)}}{\partial w^{[3]}}=-(y^{(i)}-a^{[3]})(a^{[2]})^T\]</span></p><p><span class="math display">\[\frac{\partial L^{(i)}}{\partialw^{[2]}}=-(y^{(i)}-a^{[3]})(a^{[1]})^T((w^{[3]})^T*a^{[2]}*(1-a^{[2]}))\]</span></p><p>​ where <span class="math inline">\(*\)</span> means element-wiseproduct.</p><p><strong>Improving NNs</strong>:</p><p>​ <em>Activation function</em>: these are hyper-parameters</p><ul><li><span class="math inline">\(sigmoid(z)=1/(1+e^{-z})\)</span>-:gradient vanish</li><li><span class="math inline">\(ReLU(z)=max(0,z)\)</span>, <span class="math inline">\(ReLU&#39;(z)=1\{z&gt;0\}\)</span></li><li><span class="math inline">\(\tanh(z)=(e^z-e^{-z})/({e^z+e^{-z})}\)</span>,<span class="math inline">\(\tanh&#39;(z)=1-\tanh^2(z)\)</span> [-1,1]</li></ul><p>why do we need activation function?if don't apply activation, thenetwork will lose complexity and can only do linear regression.</p><p>​ <code>Using one of these three activations in a layer</code></p><p>​ <em>Initialization method</em>:</p><p>​ Normalizing your input: make input feature vector <span class="math inline">\(\sim N(0,1)\)</span> (use calculated <span class="math inline">\(\mu,\sigma\)</span> on training set for alldataset)</p><p>​ Vanishing/Exploding gradient: For instance, we have <span class="math inline">\(L\)</span> layers NNs, and each layer except lastlayer has two nodes, the activation function is identity function (<span class="math inline">\(f(z)=z\)</span>), and bias are zero. Then thepredicted label y hat is : <span class="math display">\[\hat y=w^{[L]}w^{[L-1]}\cdots w^{[ 1]}x\]</span> if <span class="math inline">\(w^{[L-1]}\)</span> is a bitmore than <span class="math inline">\(1\)</span>, then the <span class="math inline">\(\hat y\)</span> will be <span class="math inline">\(L\)</span> exponential of parameter and explode;for the parameter less than <span class="math inline">\(1\)</span>, $y $will vanish. So we expect to have parameters to be exact <span class="math inline">\(1\)</span>.</p><p>​ Intuition: Large <span class="math inline">\(n\)</span> <span class="math inline">\(\rightarrow\)</span> small <span class="math inline">\(w\)</span>.</p><p>​ Some initialization method proved to be practical:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># For sigmoid</span></span><br><span class="line">w_l = np.random.randn(shape) * np.sqrt(<span class="number">1</span>/n_l_minus_one)</span><br><span class="line"><span class="comment"># For ReLU</span></span><br><span class="line">w_l = np.random.randn(shape) * np.sqrt(<span class="number">2</span>/n_l_minus_one)</span><br><span class="line"><span class="comment"># Xavier Intialization</span></span><br><span class="line">w_l = np.sqrt(<span class="number">1</span>/n_l_minus_one) <span class="comment"># for tanh</span></span><br><span class="line"><span class="comment"># He Initialization</span></span><br><span class="line">w_l = np.sqrt(<span class="number">2</span>/(n_l_minus_one+n_l))</span><br></pre></td></tr></table></figure><p>​ <em>Optimization</em>:</p><p>​ mini-batch gradient descent: for input <span class="math inline">\(X=(x^{(1)},x^{(2)},...,x^{(m)}),Y=(y^{(1)},y^{(2)},..,y^{(m)})\)</span>, we pack certain number ofexamples, and the input become <span class="math inline">\(X=(x^{\{1\}},...,x^{\{T\}}),Y=(y^{\{1\}},..,y^{\{T\}})\)</span></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Algo:</span><br><span class="line">For iteration t =1...:</span><br><span class="line">Select batch (x_t, y_t)</span><br><span class="line">Forward propagation</span><br><span class="line">Backward Batch</span><br><span class="line">Update w and b</span><br></pre></td></tr></table></figure><p>​ Momentum algorithm: <span class="math display">\[v=\beta v+(1-\beta)\frac{\partial L}{\partial w}\\w=w-\alpha v\]</span></p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 (Machine Learning) </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Notes for Stanford 229W course</title>
      <link href="/2022/04/06/Notes-for-Stanford-229W-course/"/>
      <url>/2022/04/06/Notes-for-Stanford-229W-course/</url>
      
        <content type="html"><![CDATA[<h3 id="what-is-this-course-about">What is this course about?</h3><p>Complex data can be represented as a graph of relationships betweenobjects. Such networks are a fundamental tool for modeling social,technological, and biological systems. This course focuses on thecomputational, algorithmic, and modeling challenges specific to theanalysis of massive graphs. By means of studying the underlying graphstructure and its features, students are introduced to machine learningtechniques and data mining tools apt to reveal insights on a variety ofnetworks. <strong>Topics include:</strong> representation learning andGraph Neural Networks; algorithms for the World Wide Web; reasoning overKnowledge Graphs; influence maximization; disease outbreak detection,social network analysis.</p><p><a href="https://www.bilibili.com/video/BV1RZ4y1c7Co?spm_id_from=333.1007.top_right_bar_window_custom_collection.content.click">[coursewebsite]</a></p><span id="more"></span><h2 id="introduction">Introduction</h2><h3 id="why-graphs">Why graphs?</h3><p>Some interesting graphs:</p><ul><li>Particle networks</li><li>Networks of neurons</li><li><strong>Molecules</strong></li><li><strong>Mesh</strong></li></ul><p>Types of Networks and Graphs</p><ul><li>Networks (also known as Natural Graphs): Biomedicine, brainconnections</li><li>Graphs: Molecules, 3D shape</li></ul><h3 id="why-is-it-hard">Why is it hard?</h3><p>Networks are complex:</p><ul><li>Arbitrary size and complex topological structure</li><li>No fixed node ordering or reference point</li><li>Often dynamic and have multimodal features</li></ul><p>Representation learning: Map nodes to d-dimensional embeddings suchthat similar nodes in the network are embedded close together.</p><p><img src="/2022/04/06/Notes-for-Stanford-229W-course/image-20210721192309546.png" alt="image-20210721192309546" style="zoom:80%;"></p><h3 id="different-types-of-tasks">Different types of tasks</h3><ul><li>Node level: Node classification - predict a property of a node e.g.categorize online users/items</li><li>Edge level: link prediction - predict whether there are missinglinks between two nodes e.g. knowledge graph completion</li><li>Graph level: Graph classification; Graph generation; graphevolution</li></ul><p><strong>Node-level example: Protein Folding</strong></p><p>​ Given a sequence of amino acids to predict protein. Treat protein asgraph, and nodes in the graph are amino acids in the protein sequence,and the edge is amino acids that are spatially close to each other</p><p><strong>Edge-level example 1: Recommender systems</strong></p><p>​ Nodes: Users and items. Edges: User-item interactions</p><p><strong>Edge-level example 2: Drug side effects</strong></p><p>​ Nodes: drugs &amp; proteins. Edges: interactions. Task: predictwhether the two drugs have interactions (edge)</p><p><strong>Subgraph-level example: Traffic prediction</strong></p><p>​ Nodes: Road segments. Edges: connectivity between road segments.Task: predict the time needed</p><p><strong>Graph-level example 1: Drug discovery</strong></p><p>​ Nodes: Atoms. Edges: Chemical bonds. Graph generation: generatingnovel molecules</p><p><strong>Graph-level example 2: Physics simulation</strong></p><p>​ Nodes: particles. Edges: Interaction between particles. Goal:predict how a graph will evolve over</p><h3 id="choice-of-graph-representation">Choice of graphrepresentation</h3><p><strong>Components of a network</strong>:</p><ul><li>Objects: nodes, vertices <span class="math inline">\(N\)</span></li><li>Interactions: links, edges <span class="math inline">\(E\)</span></li><li>System: network, graph <span class="math inline">\(G(N,E)\)</span></li></ul><p><strong>How to define a graph</strong>: what are nodes, what areedges</p><p><strong>Node degrees</strong>:</p><ul><li>Undirected: <span class="math inline">\(k_i\)</span> the number ofedges adjacent to node <span class="math inline">\(i\)</span> . Avg.degree: <span class="math inline">\(\bark=\frac{1}{N}\sum_{i=1}^Nk_i=\frac{2E}{N}\)</span></li><li>Directed: in-degree <span class="math inline">\(k_i^{in}\)</span>;out-degree <span class="math inline">\(k_i^{out}\)</span>; total degreeis the sum of in- and out-degrees. Avg. degree: <span class="math inline">\(\bar k=E/N\)</span></li></ul><p><strong>Bipartite Graph</strong>: a graph whose nodes can be dividedinto two disjoint sets <span class="math inline">\(U\)</span> and <span class="math inline">\(V\)</span> such that every link connects a node in<span class="math inline">\(U\)</span> to one in <span class="math inline">\(V\)</span>; that is, <span class="math inline">\(U\)</span> and <span class="math inline">\(V\)</span> are independent sets.</p><p><img src="/2022/04/06/Notes-for-Stanford-229W-course/image-20210721203838496.png" alt="image-20210721203838496" style="zoom:50%;"></p><p>Some examples: authors-to-papers; users-to-movies</p><p><strong>Representing Graphs</strong>:</p><ul><li>Adjacency matrix: <span class="math inline">\(A_{ij}=1\)</span> ifthere is a link from node <span class="math inline">\(i\)</span> to node<span class="math inline">\(j\)</span>, 0 otherwise. Adjacency matricesare <em>sparse</em></li><li>Adjacency list: easier to work with if network is large and sparse;quickly retrieve all neighbors of a given node</li><li>Node and edge attributes</li></ul><h2 id="traditional-methods-for-ml-on-graphs">Traditional methods for MLon graphs</h2><p>### Traditional feature-based method - nodes</p><p><strong>Goal</strong>: Characterize the structure and position of anode in the network</p><p><strong>Node features</strong></p><ul><li><p>Node degree: will treat neighboring nodes equally.</p></li><li><p>Node centrality:</p><p><em>eigenvector centrality</em>:</p></li></ul><p><span class="math display">\[c_{v}=\frac{1}{\lambda} \sum_{u \in N(v)} c_{u} \quad \leftrightarrow\quad \lambda c=A c\]</span></p><p>​ where <span class="math inline">\(\lambda\)</span> is some positiveconstant, <span class="math inline">\(c\)</span> is centrality vectorand <span class="math inline">\(A\)</span> is adjacency matrix</p><p>​ <em>betweenness centrality</em>: how important transit hub <span class="math display">\[c_{v}=\sum_{s \neq v \neq t} \frac{\#(\text { shortest paths between } s\text { and } t \text { that contain } v)}{\#(\text { shortest pathsbetween } s \text { and } t)}\]</span> ​ <em>closeness</em>: a node is important if it has smallshortest path lengths to all other nodes <span class="math display">\[c_{v}=\frac{1}{\sum_{u \neq v} \text { shortest path length between } u\text { and } v}\]</span> ​ <em>clustering coefficient</em>: how connected <span class="math inline">\(v\)</span>'s neighboring nodes are:</p><p><span class="math display">\[e_v=\frac{\#(\text { edges among neighboring nodes })}{\#(\text { nodepairs among kv\ neighboring nodes })}\]</span><img src="/2022/04/06/Notes-for-Stanford-229W-course/image-20210722185534659.png" alt="image-20210722185534659" style="zoom:50%;"></p><p>​ clustering coefficient counts the #(triangles) in theego-network</p><p><img src="/2022/04/06/Notes-for-Stanford-229W-course/image-20210722190109415.png" alt="image-20210722190109415" style="zoom:50%;"></p><p>​ <em>Graphlets</em>: rooted connected non-isomorphic subgraphs:</p><figure><img src="/2022/04/06/Notes-for-Stanford-229W-course/image-20210722190348940.png" alt="image-20210722190348940"><figcaption aria-hidden="true">image-20210722190348940</figcaption></figure><p>​ Graph degree vector(GDV): graphlet-base features for nodes. Degreecounts #(graphlets) that a node touches</p><h3 id="traditional-feature-based-method---edges">Traditionalfeature-based method - edges</h3><p><strong>Goal</strong>: predict new edges based on existing links. attest time, all node pairs (no existing links) are ranked and top <span class="math inline">\(K\)</span> node pairs are predicted. In trainingprocess, remove a random set of links and then aim to predict them. orpredicting links over time</p><p><strong>distance-based features</strong>: this does not capture thedegree of neighborhood overlap</p><p><strong>local neighborhood overlap</strong>:</p><ul><li>common neighbors:</li></ul><p><span class="math display">\[\left|N\left(v_{1}\right) \cap N\left(v_{2}\right)\right|\]</span></p><ul><li>Jaccard's coefficient:</li></ul><p><span class="math display">\[\frac{\left|N\left(v_{1}\right) \capN\left(v_{2}\right)\right|}{\left|N\left(v_{1}\right) \cupN\left(v_{2}\right)\right|}\]</span></p><ul><li><em>Adamic-Adar index</em>:</li></ul><p><span class="math display">\[\sum_{u \in N\left(v_{1}\right) \cap N\left(v_{2}\right)} \frac{1}{\log\left(k_{u}\right)}\]</span></p><p>limitation of local neighborhood features:</p><pre><code>1. metric is always zero if the two nodes do not have any neighbors in common2. however, the two nodes may still potentially be connected in the future.</code></pre><p><strong>Global neighborhood overlap</strong>:</p><ul><li><p>Katz index: count the number of paths of all lengths between agiven pair of nodes</p><p>computing paths between two nodes: Let <span class="math inline">\(P_{uv}^{(k)}\)</span> = #paths of length <span class="math inline">\(K\)</span> between <span class="math inline">\(u\)</span> and <span class="math inline">\(v\)</span>. It will be proved that <span class="math inline">\(P^{(K)}=A^K\)</span>. And Katz index is: <span class="math display">\[S_{v_1v_2}=\sum_{l=1}^\infty\beta^l A^l_{v_1v_2}\]</span></p><p>where <span class="math inline">\(0&lt;\beta^l&lt;1\)</span> isdiscount factor, and it can be computed in closed-form: <span class="math display">\[S=\sum_{i=1}^\infty\beta^iA^i=(I-\beta A)^{-1}-I\]</span></p></li></ul><h3 id="graph-level-features-and-graph-kernels">Graph-level features andgraph kernels</h3><p>Goal: We want features that characterize the structure of an entiregraph</p><p><strong>Background: kernel methods</strong>: Design kernels insteadof feature vectors</p><ul><li>Kernel <span class="math inline">\(K(G,G&#39;)\in\R\)</span>measures similarity between data</li><li>Kernel matrix <span class="math inline">\(\mathbfK=(K(G,G&#39;))_{G,G&#39;}\)</span> must always be positive semidefinite(i.e., has positive eigenvalues, of it is symmetric)</li><li>There exists a feature representation <span class="math inline">\(\phi(\cdot)\)</span> such that <span class="math inline">\(K(G,G&#39;)=\phi(G)^T\phi(G&#39;)\)</span></li><li>Once the kernel is defined, off-the-shelf ML models, such as SVM canbe used to make predictions.</li></ul><p><strong>Graphlet Features</strong>: Count the number of differentgraphlets in a graph. It should be noted that the definition ofgraphlets here is slightly different from node-level features</p><p><img src="/2022/04/06/Notes-for-Stanford-229W-course/image-20210723195113919.png" alt="image-20210723195113919" style="zoom:67%;"></p><p>Given graph <span class="math inline">\(G\)</span>, and a graphletlist <span class="math inline">\(G_{k}=(g_1,g_2,...,g_{n_k})\)</span>,define the graphlet count vector <span class="math inline">\(f_G\in\R^{n^k}\)</span> as: <span class="math display">\[\left(\boldsymbol{f}_{G}\right)_{i}=\#\left(g_{i} \subseteq G\right)\text { for } i=1,2, \ldots, n_{k}\]</span></p><p><span class="math display">\[\boldsymbol{h}_{G}=\frac{\boldsymbol{f}_{G}}{\operatorname{Sum}\left(\boldsymbol{f}_{G}\right)}\quad K\left(G, G^{\prime}\right)=\boldsymbol{h}_{G}{ }^{\mathrm{T}}\boldsymbol{h}_{G^{\prime}}\]</span></p><p><em>Limitations</em>: Counting graphlets is expensive!</p><p><strong>Weisfeiler-Lehman Kernel</strong>: use neighborhood structureto iteratively enrich node vocabulary, generalized version of bag ofnode degrees since node degrees are one-hop neighborhood information.And use <em>Color refinement</em> to achieve this.</p><p><em>Color refinement</em>:</p><ul><li>Assign an initial color <span class="math inline">\(c^{(0)}(v)\)</span> to each node <span class="math inline">\(v\)</span>;</li><li>Iteratively refine node colors by</li></ul><p><span class="math display">\[c^{(k+1)}(v)=\operatorname{HASH}\left(\left\{c^{(k)}(v),\left\{c^{(k)}(u)\right\}_{u\in N(v)}\right\}\right)\]</span></p><p>​ where HASH maps different inputs to different colors (HASHfunction).</p><p>After color refinement, WL kernel counts number of nodes with a givencolor.</p><p><strong>Comparison</strong></p><p><img src="/2022/04/06/Notes-for-Stanford-229W-course/image-20210723201836393.png" alt="image-20210723201836393" style="zoom:80%;"></p><h2 id="graph-representation-learning">Graph representationlearning</h2><h3 id="node-embedding">Node embedding</h3><p><strong>Goal</strong>: Define Encoder (ENC) and similarity(u, v) inoriginal space</p><p><img src="/2022/04/06/Notes-for-Stanford-229W-course/image-20210725085157352.png" alt="image-20210725085157352" style="zoom:80%;"></p><p><strong>Two key components</strong>:</p><ul><li>Encoder: maps each node to a low-dimensional vector</li></ul><p><span class="math display">\[\text{ENC}(v)=z_v\]</span></p><p>where <span class="math inline">\(z_v\)</span> is a d-dimensionalvector (d usually be set to 64-1000)</p><ul><li>Decoder: Find a function that can similar with the similarity in theoriginal network:</li></ul><p><span class="math display">\[\text{similarity}(u,v)\simeq z_v^Tz_u\]</span></p><p>In this work, we use dot-product as our decoder</p><p><strong>"Shallow" Encoding</strong>: the simplest encoding approach:<span class="math display">\[\text{ENC}(v)=z_v=Z\cdot v\]</span> where <span class="math inline">\(Z\in\R^{d\times|\mathcal{V}|}\)</span> is a matrixand each column is a node embedding. <span class="math inline">\(v\in\mathbb{I}^{|\mathcal{V}|}\)</span> is aindicator vector, all zeroes except a one in column indication node<span class="math inline">\(v\)</span>.</p><p><em>Limitation</em>: for large graph, the matrix <span class="math inline">\(Z\)</span> will be very large</p><p><code>Node embedding is unsupervised/self-superviesed approah</code></p><h3 id="random-walk-approaches-for-node-embeddings">Random walkapproaches for node embeddings</h3><p><strong>Notation</strong>:</p><ul><li>Vector <span class="math inline">\(z_u\)</span>: the embeddings ofnode <span class="math inline">\(u\)</span></li><li>Probability <span class="math inline">\(P(v|z_u)\)</span>: Theprobability of visiting node <span class="math inline">\(v\)</span> onrandom walks starting from node <span class="math inline">\(u\)</span></li></ul><p><strong>Random Walk</strong>: Given a graph and a starting point, weselect a neighbor of it at random, and move to this neighbor, etc. Therandom sequence of points visited this way is a random walk on thegraph.</p><p><em>Similarity</em>: probability that <span class="math inline">\(u\)</span> and <span class="math inline">\(v\)</span> occur on a random walk over thegraph</p><p><strong>Why random walk</strong>:</p><ul><li>expressivity: incorporates both local and higher-order neighborhoodinformation</li><li>efficiency: only need to consider pairs that co-occur on randomwalks</li></ul><p><strong>Unsupervised feature learning</strong>:</p><ul><li>intuition: find embedding of nodes in d-dimensional space thatpreserves similarity</li><li>idea: learn node embedding such that nearby nodes are close togetherin the network</li><li>given a node <span class="math inline">\(u\)</span>, how do wedefine nearby nodes? sequence from <span class="math inline">\(u\)</span> to <span class="math inline">\(v\)</span></li></ul><p><strong>Feature learning as optimization</strong>:</p><ul><li>Given <span class="math inline">\(G=(V,E)\)</span></li><li>Goal is to learn a mapping <span class="math inline">\(f:u\rightarrow \R^d\)</span> : <span class="math inline">\(f(u)=z_u\)</span></li><li>Objective function:</li></ul><p><span class="math display">\[\max_f \sum_{u\in V}\log P(N_R(u)|z_u)\]</span></p><p>​ where <span class="math inline">\(N_R(u)\)</span> is theneighborhood of node <span class="math inline">\(u\)</span> by strategy<span class="math inline">\(R\)</span></p><ul><li>Given node <span class="math inline">\(u\)</span>, we want to learnfeature representations that are predictive of the nodes in its randomwalk neighborhood <span class="math inline">\(N_R(u)\)</span></li></ul><p><strong>Random walk optimization</strong></p><ul><li><p>Run short fixed-length random walks starting from each node <span class="math inline">\(u\)</span> in the graph using some random walkstrategy <span class="math inline">\(R\)</span></p></li><li><p>For each node <span class="math inline">\(u\)</span> collect<span class="math inline">\(N_R(u)\)</span>, the multiset of nodesvisited on random walks starting from <span class="math inline">\(u\)</span></p></li><li><p>Optimize embeddings according to: Given node <span class="math inline">\(u\)</span>, predict its neighbors <span class="math inline">\(N_R(u)\)</span></p></li><li><p>the objective function can be written as equivalently :</p></li></ul><p><span class="math display">\[\sum_{u\in V}\sum_{v\in N_R(u)}-\log(P(v|z_u))\]</span></p><ul><li>Parameterize <span class="math inline">\(P(v|z_u)\)</span> usingsoftmax:</li></ul><p><span class="math display">\[P(v|z_u)=\frac{\exp(z_u^Tz_v)}{\sum_{n\in V}\exp(z_u^Tz_n)}\]</span></p><ul><li>the time complexity is <span class="math inline">\(n^2\)</span>because there are two summations of all node in the loss function</li></ul><p><em>Negative sampling</em>: solve the time complexity is <span class="math inline">\(n^2\)</span> <span class="math display">\[\begin{align}&amp;\log \left(\frac{\exp \left(\mathbf{z}_{u}^{\mathrm{T}}\mathbf{z}_{v}\right)}{\sum_{n \in V} \exp\left(\mathbf{z}_{u}^{\mathrm{T}} \mathbf{z}_{n}\right)}\right)\\\simeq&amp;\log \left(\sigma\left(\mathbf{z}_{u}^{\mathrm{T}}\mathbf{z}_{v}\right)\right)-\sum_{i=1}^{k} \log\left(\sigma\left(\mathbf{z}_{u}^{\mathrm{T}}\mathbf{z}_{n_{i}}\right)\right), n_{i} \sim P_{V}\end{align}\]</span> ​ sample <span class="math inline">\(k\)</span> negative nodeseach with probability proportional to its degree. There are twoconsiderations for <span class="math inline">\(k\)</span> (# negativesamples):</p><ol type="1"><li>Higher <span class="math inline">\(k\)</span> gives more robustestimates</li><li>Higher <span class="math inline">\(k\)</span> corresponds to higherbias on negative events.</li></ol><p>In practice <span class="math inline">\(k=5-20\)</span></p><p><strong>node2vec</strong>:</p><ul><li><p>Simplest idea: Just run fixed-length, unbiased random walksstarting from each node. But the issue is that such notion of similarityis too constrained.</p></li><li><p>node2vec: key observation - Flexible notion of networkneighborhood <span class="math inline">\(N_R(u)\)</span> of node <span class="math inline">\(u\)</span> leads to rich node embeddings; Developbiased <span class="math inline">\(2^{nd}\)</span> order random walk<span class="math inline">\(R\)</span> to generate network neighborhood<span class="math inline">\(N_R(u)\)</span> of node <span class="math inline">\(u\)</span>.</p><p>​ Idea: use flexible, biased random walks that can trade off betweenlocal and global views of the network.</p><p>​ Biased walk: Use two classic strategies to define a neighborhood<span class="math inline">\(N_R(u)\)</span> of a given node <span class="math inline">\(u\)</span>. one is depth-first search (DFS) andbreadth-first search (BFS)</p></li></ul><p><img src="/2022/04/06/Notes-for-Stanford-229W-course/image-20210725150836335.png" alt="image-20210725150836335" style="zoom:67%;"></p><p>​ BFS: Micro-view of neighborhood; DFS: Macro-view of neighborhood</p><p><strong>Interpolating BFS and DFS</strong>: Biased fixed-lengthrandom walk <span class="math inline">\(R\)</span> that given a node<span class="math inline">\(u\)</span> generates neighborhood <span class="math inline">\(N_R(u)\)</span>. There are twohyper-parameters:</p><ul><li>Return parameter <span class="math inline">\(p\)</span>: Return backto the previous node</li><li>In-out parameter <span class="math inline">\(q\)</span>: Movingoutwards (DFS) vs. inward (BFS); Intuitively <span class="math inline">\(q\)</span> is the "ratio" of BFS vs. DFS</li></ul><p><strong>Biased Random walks</strong>: Biased <span class="math inline">\(2^{nd}\)</span>-order random walks explore networkneighborhoods - Ran. walk just traversed edge <span class="math inline">\((s_1,w)\)</span> and is now at <span class="math inline">\(w\)</span></p><p><img src="/2022/04/06/Notes-for-Stanford-229W-course/image-20210725181225105.png" alt="image-20210725181225105" style="zoom: 67%;"></p><p><img src="/2022/04/06/Notes-for-Stanford-229W-course/image-20210725181513298.png" alt="image-20210725181513298" style="zoom:67%;"></p><p><strong>node2vec algorithm</strong>:</p><ol type="1"><li><p>Compute random walk probabilities</p></li><li><p>Simulate <span class="math inline">\(r\)</span> random walks oflength <span class="math inline">\(l\)</span> starting from each node<span class="math inline">\(u\)</span></p></li><li><p>Optimize the node2vec objective using SGD</p><p><em>Linear-time complexity</em> and All 3 steps are <em>individuallyparallelizable</em></p></li></ol><p><strong>Other Random walk ideas</strong>:</p><p><img src="/2022/04/06/Notes-for-Stanford-229W-course/image-20210725181953504.png" alt="image-20210725181953504" style="zoom:67%;"></p><h3 id="embedding-entire-graph">Embedding entire graph</h3><p><strong>Goal</strong>: Want to embed a subgraph or an entire graph<span class="math inline">\(G\)</span> to an embedding <span class="math inline">\(z_G\)</span></p><p><strong>Simple idea</strong>: Run a standard node embedding techniqueon the graph <span class="math inline">\(G\)</span> to get <span class="math inline">\(z_v\)</span> then just sum or average the nodeembeddings in the graph <span class="math inline">\(G\)</span> <span class="math display">\[z_G=\sum_{v\in G}z_v\]</span> <strong>Introduce "virtual node"</strong>: to represent thegraph and run a standard graph embedding technique (the virtual nodewill connect to every node in the graph)</p><p><strong>Anonymous walk embeddings</strong>:</p><p><img src="/2022/04/06/Notes-for-Stanford-229W-course/image-20210725184028562.png" alt="image-20210725184028562" style="zoom:67%;"></p><p>​ Unlike the random walk taking the neighbor sequence in the randomwalk, the anonymous walk embeddings is to get the sequence of times whennode was first visited. However, the number of walks growexponentially.</p><p><strong>Simple Use of Anonymous Walks</strong>:</p><p>​ Simulate anonymous walks <span class="math inline">\(w_i\)</span> of<span class="math inline">\(l\)</span> steps and record their counts.Then represent the graph as a probability distribution over these walks.For example: set <span class="math inline">\(l\)</span>=3, then we canrepresent the graph as 5-dim vector (111, 112, 121, 122, 123) as <span class="math inline">\(w_i\)</span>. Use <span class="math inline">\(Z_G[i]\)</span> as probability of anonymous walk<span class="math inline">\(w_i\)</span> in <span class="math inline">\(G\)</span>.</p><p><strong>Sampling Anonymous</strong>:</p><p>​ Generate independently a set of <span class="math inline">\(m\)</span> random walks and represent the graph asa probability distribution over these walks. the <span class="math inline">\(m\)</span> can be decided if we want thedistribution to have error of more than <span class="math inline">\(\epsilon\)</span> with probability less than <span class="math inline">\(\delta\)</span>: <span class="math display">\[m=[\frac{2}{\epsilon^2}(\log(2^\eta-2)-\log(\delta))]\]</span> where <span class="math inline">\(\eta\)</span> is the totalnumber of anno. walks of length <span class="math inline">\(l\)</span>.</p><p><strong>Learn walk embeddings</strong>:</p><ul><li>Run <span class="math inline">\(T\)</span> different random walksfrom <span class="math inline">\(u\)</span> each of length <span class="math inline">\(l\)</span>:</li></ul><p><span class="math display">\[N_R(u)={\{w_1^u,w_2^u,...,w_T^u\}}\]</span></p><ul><li><p>Learn to predict walks that co-occur in <span class="math inline">\(\Delta-size\)</span> window</p></li><li><p>the objective function is similar to random walk but thedifference is that we don't predict the neighbor but the sequence ofanon. walks.</p></li></ul><p><span class="math display">\[\max_{Z,d}\frac{1}{T}\sum_{t=\Delta}^{T-\Delta}\log P(w_t|\{w_{t-\Delta},...,w_{t+\Delta},z_G\})\]</span></p><p>where: <span class="math display">\[P(w_t|\{w_{t-\Delta},...,w_{t+\Delta},z_G\})=\frac{\exp(y(w_t))}{\sum_{i=1}^\eta\exp(y(w_i))}\]</span></p><p><span class="math display">\[y(w_t)=b+U\cdot(cat(\frac{1}{2\Delta}\sum_{i=-\Delta}^{\Delta}z_i,z_G))\]</span></p><p>and the <span class="math inline">\(b\in\R\)</span> and <span class="math inline">\(U\in\R^D\)</span> are learnable parameters.</p><h2 id="graph-as-matrix">Graph as Matrix</h2><h3 id="pagerank">PageRank</h3><p>​ Web as a graph: nodes - web pages; edges - hyperlinks</p><p><strong>The "Flow" model</strong>: A vote from an important page isworth more</p><p><img src="/2022/04/06/Notes-for-Stanford-229W-course/image-20210729203110106.png" alt="image-20210729203110106" style="zoom:80%;"></p><p>As above figure shows, the node <span class="math inline">\(i\)</span> has there out-links, and one of thelinks votes on node <span class="math inline">\(j\)</span>, thereforethe 1/3 importance of <span class="math inline">\(i\)</span> (<span class="math inline">\(r_i\)</span>) flows to node <span class="math inline">\(j\)</span>. Similarly, the importance of node<span class="math inline">\(j\)</span> has 1/3 splits to other nodes.<span class="math display">\[r_j=\sum_{i\rightarrow j}\frac{r_i}{d_i}\]</span> where <span class="math inline">\(d_i\)</span> is theout-degree of node <span class="math inline">\(i\)</span>.</p><p><em>Stochastic adjacency matrix M</em>: Let node <span class="math inline">\(j\)</span> have <span class="math inline">\(d_j\)</span> out-links. If <span class="math inline">\(j\rightarrow i\)</span>, then <span class="math inline">\(M_{ij}=\frac{1}{d_j}\)</span>. And <span class="math inline">\(M\)</span> is a column stochastic matrix becausethe columns sum to 1.</p><p><em>Rank vector r</em>: An entry per page. <span class="math inline">\(\sum_i r_i=1\)</span>.</p><p>Then the flow equations can be written as: <span class="math display">\[r=M\cdot r\]</span> <em>Connection to Random Walk</em>:</p><p>​ Imagine a random web surfer who is on some page <span class="math inline">\(i\)</span> at time <span class="math inline">\(t\)</span>, and at time <span class="math inline">\(t+1\)</span>, it follows an out-link from <span class="math inline">\(i\)</span> uniformly at random, finally ends up onsome page <span class="math inline">\(j\)</span> linked from <span class="math inline">\(i\)</span>. Process repeats indefinitely. Let<span class="math inline">\(p(t)\)</span> be the vector whose <span class="math inline">\(i^{th}\)</span> coordinates is the probabilitythat the surfer is at page <span class="math inline">\(i\)</span> attime <span class="math inline">\(t\)</span>. The stationary distributionof a random walk is <span class="math display">\[p(t)=M\cdot p(t)\]</span> <em>Connection to eigenvector centrality</em>: <span class="math display">\[\lambda c=Ac\]</span> <em>Eigenvector formulation</em>: the rank vector <span class="math inline">\(r\)</span> is an eigenvector of the stochasticadjacent matrix <span class="math inline">\(M\)</span> with eigenvalue1. The <span class="math inline">\(r=M\cdot(M\cdot(...(M\cdotu)))\)</span> is the solution of above equation.</p><h3 id="solve-the-pagerank-problem">Solve the PageRank problem</h3><p><strong>Power iteration method</strong>:</p><ul><li><p>initialize: <span class="math inline">\(r^0=[1/N,...,1/N]^T\)</span></p></li><li><p>iterate: <span class="math inline">\(r^{(t+1)}=M\cdotr^t\)</span></p></li><li><p>stop when <span class="math inline">\(|r^{(t+1)}-r^t|_1&lt;\epsilon\)</span> (where<span class="math inline">\(|x|_1=\sum_1^N|x_1|\)</span> is theL<sub>1</sub> norm)</p></li></ul><p>about 50 iterations is sufficient to estimate the limitingsolution.</p><p><strong>Three questions</strong>:</p><ul><li>Does this converge?</li><li>Does it converge to what we want?</li><li>Are results reasonable?</li></ul><p><strong>Two problems</strong>:</p><ul><li>Some pages are dead ends (have no out-links), such pages causeimportance to "leak out"</li></ul><p><img src="/2022/04/06/Notes-for-Stanford-229W-course/image-20210731133922246.png" alt="image-20210731133922246" style="zoom: 67%;"></p><ul><li>Spider traps: all out-links are within the group, and eventuallyspider traps absorb all importance.</li></ul><p><img src="/2022/04/06/Notes-for-Stanford-229W-course/image-20210731133906876.png" alt="image-20210731133906876" style="zoom:67%;"></p><p><strong>Solution to two problems</strong>:</p><p><em>Spider traps</em>: At each time step, the random surfer has twooptions. With probability <span class="math inline">\(\beta\)</span>follow a link at random, with <span class="math inline">\(1-\beta\)</span> jump to a random page (commonvalues for <span class="math inline">\(\beta\)</span> are in the range0.8 to 0.9)</p><p><em>Dead ends</em>: Follow random teleports links with totalprobability 1.0 from dead-ends</p><p>Spider-traps are not a problem, but with traps PageRank scores arenot what we want; Dead-ends are a problem because the matrix is notcolumn stochastic so our initial assumptions are note met.</p><p><em>Google's solution that does it all</em>: <span class="math display">\[r_j=\sum_{i\rightarrow j}\beta\frac{r_i}{d_i}+(1-\beta)\frac{1}{N}\]</span> Then the matrix <span class="math inline">\(M\)</span> changeto the Google matrix <span class="math inline">\(G\)</span>: <span class="math display">\[G=\beta M+(1-\beta)[\frac{1}{N}]_{N\times N}\]</span></p><h3 id="random-walk-with-restarts-and-personalized-pagerank">Random walkwith restarts and personalized PageRank</h3><p><strong>Tasks</strong>: Recommendation.</p><p><strong>Goal</strong>: Proximity on graphs. What items should werecommend to a user who interacts with item Q?</p><p>the intuition is if items Q and P are interacted by similar users,recommend P when user interacts with Q.</p><p><strong>Personalized PageRank</strong>: The user teleports to nodes Swhich is the subset of the user may be interested in.</p><p><strong>Random walks with restarts</strong>: teleport to the startingnode: S = {Q} where Q is the starting node.</p><ul><li>Given a set of QUERY_NODES</li><li>Make a step to a random neighbor and record the visit</li><li>With probability ALPHA, restart the walk at one of theQUERY_NODES</li><li>The nodes with the highest visit have highest proximity to theQUERY_NODES.</li></ul><h3 id="matrix-factorization-and-node-embeddings">Matrix factorizationand node embeddings</h3><p>​ For node embedding task, our goal is maximize <span class="math inline">\(z_u^Tz_v\)</span> if nodes <span class="math inline">\(u,v\)</span> are similar. And the key is how tojudge the two nodes are similar.</p><p><strong>Simplest node similarity</strong>: Nodes <span class="math inline">\(u,v\)</span> are similar if they are connected byan edge. (<span class="math inline">\(z_u^Tz_v=A_{v,u}\)</span>).Because learn a matrix satisfying <span class="math inline">\(A-Z^TZ\)</span> is generally impossible. We canlearn <span class="math inline">\(Z\)</span> approximately. and theobjective is <span class="math inline">\(\min_Z||A-Z^TZ||_2\)</span></p><p><strong>Random walk-based similarity</strong>: <span class="math display">\[\log(vol(G)(\frac{1}{T}\sum_{r=1}^T(D^{-1}A)^r)D^{-1})-\log b\]</span><img src="/2022/04/06/Notes-for-Stanford-229W-course/image-20210731193947925.png" alt="image-20210731193947925" style="zoom:67%;"></p><p>If we change the matrix <span class="math inline">\(A\)</span> in thesimplest similarity, then we actually do the Deep walk now.</p><p><strong>Limitations of network embedding</strong>:</p><ul><li>Cannot obtain embeddings for nodes not in the training set. In otherword, it is difficult for network embedding to solve the dynamicgraph.</li><li>DeepWalk and node2vec do not capture structural similarity</li><li>Cannot utilize node, edge and graph features</li></ul><h2 id="message-passing-and-node-classification">Message passing andnode classification</h2><p><strong>Main question</strong>: Given a network with labels on somenodes, how do we predict labels to all other nodes in the network.(semi-supervised node classification)</p><p><strong>Intuition</strong>: Correlations exist in networks, in otherwords, similar nodes are connected. The correlation means that nearbynodes have the same color (label).</p><p><strong>Two dependencies that lead to correlation</strong>:</p><ul><li>Homophily: people of similar characteristics tend to link eachother</li><li>Influence: Social connections influence our own characteristic</li></ul><p><strong>Classification label of a node v may depend on</strong>:</p><ul><li>Features of <span class="math inline">\(v\)</span></li><li>Labels of the nodes in <span class="math inline">\(v\)</span>'sneighborhood</li><li>Features of the nodes in <span class="math inline">\(v\)</span>'sneighborhood</li></ul><p><strong>Example task</strong>:</p><ul><li>Let <span class="math inline">\(A\)</span> be a <span class="math inline">\(n\times n\)</span> adjacency matrix over <span class="math inline">\(n\)</span> nodes</li><li>Let <span class="math inline">\(Y=\{0,1\}^n\)</span> be a vector oflabels. (the unlabeled node is denoted by unlabeled)</li><li>Goal: predict the unlabeled nodes are likely to be Class 0 or Class1</li></ul><p><strong>Markov assumption</strong>: (first order) the label <span class="math inline">\(Y_v\)</span> of node <span class="math inline">\(v\)</span> depends on the labels of its neighbor<span class="math inline">\(N_v\)</span></p><p><strong>Solution</strong>: We use three classifier to give thesolution of the task.</p><figure><img src="/2022/04/06/Notes-for-Stanford-229W-course/image-20210804201531938.png" alt="image-20210804201531938"><figcaption aria-hidden="true">image-20210804201531938</figcaption></figure><p><em>Local classifier</em>:</p><ul><li>predicts label based on node features</li><li>standard classification task</li><li>does not use network information</li></ul><p><em>Relational classifier</em>:</p><ul><li>predicts label based on the labels and node features of itsneighbors</li><li>use network information</li></ul><p><em>Collective inference</em>:</p><ul><li>apply relational classifier to each node iteratively</li><li>iterate until the inconsistency between neighboring labels isminimized</li><li>network structure affects the final prediction</li></ul><h3 id="probabilistic-relational-classifier">Probabilistic RelationalClassifier</h3><p><strong>Relational classifier</strong>:</p><p><em>Basic idea</em>: Class probability <span class="math inline">\(Y_v\)</span> of node <span class="math inline">\(v\)</span> is a weighted average of classprobabilities of its neighbors. (For unlabeled nodes, initialize <span class="math inline">\(Y_v\)</span>=0.5)</p><p><em>Train</em>: Update for each node <span class="math inline">\(v\)</span> and label <span class="math inline">\(c\)</span> (e.g. 0 or 1) <span class="math display">\[P\left(Y_{v}=c\right)=\frac{1}{\sum_{(v, u) \in E} A_{v, u}} \sum_{(v,u) \in E} A_{v, u} P\left(Y_{u}=c\right)\]</span> <em>Challenges</em>:</p><ul><li>convergence is not guaranteed</li><li>model cannot use node feature information</li></ul><p><strong>Iterative classification</strong>:</p><p><em>main idea</em>: classify node <span class="math inline">\(v\)</span> based on its attributes <span class="math inline">\(f_v\)</span> as well as labels <span class="math inline">\(z_v\)</span> of neighbor set <span class="math inline">\(N_v\)</span>.</p><p><em>approach</em>: train two classifiers</p><ul><li><span class="math inline">\(\Phi_1(f_v)\)</span> = predict nodelabel based on node feature vector <span class="math inline">\(f_v\)</span></li><li><span class="math inline">\(\Phi_2(f_v, z_v)\)</span> = predictlabel based on node feature vector <span class="math inline">\(f_v\)</span> and summary <span class="math inline">\(z_v\)</span> of labels of <span class="math inline">\(v\)</span>'s neighbors.</li></ul><p><em>architecture</em>:</p><ul><li>phase 1 (train): train classifiers (e.g. neural networks) <span class="math inline">\(\Phi_1(f_v)\)</span> and <span class="math inline">\(\Phi_2(f_v, z_v)\)</span></li><li>phase 2 (test): iterate till convergence. set labels <span class="math inline">\(Y_v\)</span> based on the classifier <span class="math inline">\(\Phi_1\)</span>, compute <span class="math inline">\(z_v\)</span> and predict the labels with <span class="math inline">\(\Phi_2\)</span>. repeat for each node <span class="math inline">\(v\)</span>, and iterate until class labelsstabilize or max number of iterations is reached.</li></ul><h3 id="belief-propagation-massage-passing">Belief propagation (massagepassing)</h3><p>​ <em>Belief propagation</em> is a dynamic programming approach toanswering probability queries in a graph.</p><p><strong>Notation</strong>:</p><ul><li>Label-label potential matrix <span class="math inline">\(\boldsymbol{\psi}\)</span> : <span class="math inline">\(\boldsymbol{\psi}\left(Y_{i},Y_{j}\right)\)</span> is proportional to the probability of a node <span class="math inline">\(j\)</span> being in class <span class="math inline">\(Y_j\)</span> given that it has neighbor <span class="math inline">\(i\)</span> in class <span class="math inline">\(Y_i\)</span>.</li><li>Prior belief <span class="math inline">\(\boldsymbol{\phi}\)</span>:<span class="math inline">\(\boldsymbol {\phi}(Y_i)\)</span> isproportional to the probability of node <span class="math inline">\(i\)</span> being in class <span class="math inline">\(Y_i\)</span></li><li><span class="math inline">\(m_{i\rightarrow j}(Y_j)\)</span> is<span class="math inline">\(i\)</span>'s message / estimate of node<span class="math inline">\(j\)</span> being in class <span class="math inline">\(Y_j\)</span></li><li><span class="math inline">\(\mathcal{L}\)</span> is the set of allclasses/labels</li></ul><p><strong>Loopy BP algorithm</strong>:</p><ul><li>Initialize all messages to 1</li><li>Repeat for each node:</li></ul><p><span class="math display">\[m_{i \rightarrow j}\left(Y_{j}\right)=\sum_{Y_{i} \in \mathcal{L}}\psi\left(Y_{i}, Y_{j}\right) \phi_{i}\left(Y_{i}\right)\prod_{k \inN_{i} \backslash \mathbf{j}} m_{k \rightarrow i}\left(Y_{i}\right)\quad\forall Y_{j} \in \mathcal{L}\]</span></p><ul><li>After convergence:</li></ul><p><span class="math display">\[b_{i}\left(Y_{i}\right)=\phi_{i}\left(Y_{i}\right) \Pi_{j \in N_{i}}m_{j \rightarrow i}\left(Y_{j}\right), \forall Y_{i} \in \mathcal{L}\]</span></p><p><strong>Limitations</strong>: hard to be applied in the loop-dominategraphs; convergence is not guaranteed, especially if many closedloops.</p><p><strong>Advantages</strong>: Easy to program &amp; parallelize; canapply to any graph models with any form of potentials.</p><h2 id="graph-neural-networks-1-gnn-model">Graph Neural Networks 1: GNNModel</h2><h3 id="introduction-1">Introduction</h3><p><strong>two key components</strong>: Encoder and decoder (similarityfunction)</p><p><strong>shallow encoding</strong>: embedding vector for each node</p><p><em>limitations</em>:</p><ul><li><span class="math inline">\(O(V)\)</span> parameters are needed.Every node has its own unique embedding, no parameters sharing</li><li>inherently "transductive" : cannot generate embeddings for nodesthat are not seen during training.</li><li>do not incorporate node features</li></ul><p><strong>deep graph encoders</strong>:</p><h3 id="basics">Basics</h3><p><strong>machine learning as optimization</strong>: <span class="math display">\[\min_\Theta\mathcal{L}(y,f(x))\]</span></p><h3 id="deep-learning-for-graphs">Deep learning for graphs</h3><p><strong>Node features</strong>: when there is no node feature in thegraph dataset, we can use <em>indicator vectors</em>. <em>vector ofconstant 1</em> or <em>node degree</em></p><p><strong>A naive approach</strong>: use adjacency matrix and featuresas input, and feed them in to DNN. The issues with this idea</p><ul><li><span class="math inline">\(O(|V|)\)</span> parameters-</li><li>not applicable to graph of different sizes</li><li>sensitive to node ordering</li></ul><p><strong>Idea</strong>: aggregate neighbors (message passing)</p><ul><li>each node have a network architecture, the depth of the network canbe arbitrary depth</li><li>aggregation operator should be permutation invariant because thenode don't have order</li><li><ol type="1"><li>average messages from neighbors; 2) apply neural network</li></ol></li></ul><p><strong>Example</strong>:</p><p><img src="/2022/04/06/Notes-for-Stanford-229W-course/image-20210824211306785.png" alt="image-20210824211306785" style="zoom: 67%;"></p><p><strong>How to train the model</strong>:</p><ul><li>all node use same parameter matrix <span class="math inline">\(W_l\)</span> and <span class="math inline">\(B_l\)</span></li><li>written by matrix formula</li></ul><p><span class="math display">\[H^{(l+1)}=\sigma\left(\tilde{A} H^{(l)} W_{l}^{\mathrm{T}}+H^{(l)}B_{l}^{\mathrm{T}}\right)\]</span></p><p>where <span class="math inline">\(\tilde{A}=D^{-1}A\)</span></p><ul><li>unsupervised training use the intuition that similar nodes havesimilar embeddings</li></ul><p><span class="math display">\[\mathcal{L}=\sum_{z_{u}, z_{v}} \operatorname{CE}\left(y_{u, v},\operatorname{DEC}\left(z_{u}, z_{v}\right)\right)\]</span></p><p>where <span class="math inline">\(y_{u,v}=1\)</span> when node <span class="math inline">\(u\)</span> and <span class="math inline">\(v\)</span> are similar</p><ul><li>our model has inductive capability because the same parameters areshared for all nodes</li><li>the amount of parameters only depend on the number of features butnot the size of the graph</li></ul><h3 id="graphsage-idea">GraphSAGE idea</h3><p><span class="math display">\[\mathrm{h}_{v}^{(l+1)}=\sigma\left(\left[\mathrm{W}_{l} \cdot\mathrm{AGG}\left(\left\{\mathrm{h}_{u}^{(l)}, \forall u \inN(v)\right\}\right), \mathrm{B}_{l} \mathrm{~h}_{v}^{(l)}\right]\right)\]</span></p><p>where AGG can be: (AGG is the mean 创新点 of GraphSAGE)</p><p><img src="/2022/04/06/Notes-for-Stanford-229W-course/image-20210824215101872.png" alt="image-20210824215101872" style="zoom: 33%;"></p><h2 id="graph-neural-networks-2-design-space">Graph neural networks 2:design space</h2><h3 id="a-generative-perspective-on-gnn">a generative perspective onGNN</h3><ul><li>node's neighborhood defines a computation graph</li><li>nodes aggregate information from their neighbors using neuralnetworks</li><li>GNN Layer = message + aggregation</li><li>raw input graph != computational graph</li></ul><h3 id="a-single-gnn-layer">a single GNN layer</h3><p><strong>message computation</strong>: <span class="math display">\[\mathbf{m}_{u}^{(l)}=\mathrm{MSG}^{(l)}\left(\mathbf{h}_{u}^{(l-1)}\right)\]</span> for example: a linear layer <span class="math inline">\(m_u^{(l)}=W^{(l)}h_u^{(l-1)}\)</span>. usually itis a linear function</p><p><strong>aggregation</strong>: <span class="math display">\[\mathbf{h}_{v}^{(l)}=\operatorname{AGG}^{(l)}\left(\left\{\mathbf{m}_{u}^{(l)},u \in N(v)\right\}\right)\]</span> for example: Sum, Mean or Max aggregator (order invariant)<span class="math display">\[\mathbf{h}_{v}^{(l)}=\operatorname{CONCAT}\left(\operatorname{AGG}\left(\left\{\mathbf{m}_{u}^{(l)},u \in N(v)\right\}\right),\mathbf{B}^{(l)}h_v^{l-1}\right)\]</span> <strong>issue</strong>: information from node <span class="math inline">\(v\)</span> itself could get lost. There are twosolutions:</p><ul><li>compute message from node <span class="math inline">\(v\)</span>itself. Using a different message computation:</li></ul><p><span class="math display">\[\mathbf{m}_{v}^{(l)}=\mathbf{B}^{(l)} \mathbf{h}_{v}^{(l-1)}\]</span></p><ul><li>aggregate the message from node <span class="math inline">\(v\)</span> itself (concatenation orsummation)</li></ul><p><span class="math display">\[\mathbf{h}_{v}^{(l)}=\operatorname{CONCAT}\left(\operatorname{AGG}\left(\left\{\mathbf{m}_{u}^{(l)},u \in N(v)\right\}\right), \mathbf{m}_{v}^{(i)}\right)\]</span></p><ul><li>Nonlinearity (activation): can be added to message oraggregation</li></ul><p><strong>Classical GNN Layer</strong>:</p><p><em>GCN</em>: <span class="math display">\[\mathbf{h}_{v}^{(l)}=\sigma\left(\sum_{u \in N(v)} W^{(l)}\frac{\mathbf{h}_{u}^{(i-1)}}{|N(v)|})\right)\]</span> where message function is <span class="math inline">\(\mathbf{m}_{u}^{(l)}=\frac{1}{|N(v)|}\mathbf{W}^{(l)} \mathbf{h}_{u}^{(l-1)}\)</span>; and aggregation issummation then apply activation.</p><p><em>GraphSAGE</em>: <span class="math display">\[\mathbf{h}_{v}^{(l)}=\sigma\left(\mathbf{W}^{(l)} \cdot\operatorname{CONCAT}\left(\mathbf{h}_{v}^{(l-1)},\operatorname{AGG}\left(\left\{\mathbf{h}_{u}^{(l-1)}, \forall u \inN(v)\right\}\right)\right)\right)\]</span> where message is computed within the <span class="math inline">\(\operatorname{AGG}(\cdot)\)</span>; theaggregation is two-stage that first aggregate from node neighbors andthen aggregate over the node itself. Neighbor aggregation can be:</p><ul><li><p>Mean: <span class="math inline">\({\mathrm{AGG}}=\sum_{u \inN(v)} \frac{\mathbf{h}_{u}^{(l-1)}}{|N(v)|}\)</span></p></li><li><p>Pool: <span class="math inline">\(\mathrm{AGG}=\operatorname{Mean}\left(\left\{\mathrm{MLP}\left(\mathbf{h}_{u}^{(l-1)}\right),\forall u \in N(v)\right\}\right)\)</span></p></li><li><p>LSTM</p></li></ul><p>the model also use l2 normalization to <span class="math inline">\(h_v^{(l)}\)</span> at every layer: <span class="math display">\[\mathbf{h}_{v}^{(l)} \leftarrow\frac{\mathbf{h}_{v}^{(l)}}{\left\|\mathbf{h}_{v}^{(l)}\right\|_{2}},\forall v \in V\]</span> it means the length of node vector is always equal to 1.</p><p><em>GAT</em>: <span class="math display">\[\mathbf{h}_{v}^{(l)}=\sigma\left(\sum_{u \in N(v)} \alpha_{v u}\mathbf{W}^{(l)} \mathbf{h}_{u}^{(l-1)}\right)\]</span> for GCN/GraphSAGE, the <span class="math inline">\(\alpha_{uv}=1/|N(v)\)</span> <span class="math display">\[e_{v u}=a\left(\mathbf{W}^{(l)} \mathbf{h}_{u}^{(l-1)}, \mathbf{W}^{(l)}\boldsymbol{h}_{v}^{(l-1)}\right)\]</span></p><p><span class="math display">\[\alpha_{v u}=\frac{\exp \left(e_{v u}\right)}{\sum_{k \in N(v)} \exp\left(e_{v k}\right)}\]</span></p><p><strong>GNN Layer in Practice</strong>:</p><p><em>Batch Normalization</em>: given a batch of inputs, re-center thenode embeddings into zero mean, re-scale the variance into unitvariance, finally apply a linear transform on node embedding.</p><p><em>Dropout</em>: during training with some probability <span class="math inline">\(p\)</span>, randomly set neurons to zeros</p><p><em>Activation</em>: PReLU empirically performs better than ReLU</p><h3 id="stacking-layers-in-gnn">Stacking Layers in GNN</h3><p>The issue of stacking many GNN layers: GNN suffers from theover-smoothing problem, that is to say all the node embeddings convergeto the same value.</p><p><strong>receptive field</strong>: the set of nodes that determine theembedding of a node of interest.</p><p><strong>over-smoothing</strong>: if stack many GNN layers, nodes willhave highly-overlapped receptive fields, the node embeddings will behighly similar.</p><p><strong>how to overcome over-smoothing problem</strong>:</p><ul><li>Be cautious when adding GNN layers</li><li>increase the expressive power within each GNN layer. which means wecan make aggregation / transformation become a deep neural network!</li><li>add layers that do not pass messages: we can add MLP layers beforeafter GNN layers as pre-process layers and post-process layers</li><li>add skip connections in GNNs</li></ul><h2 id="graph-augmentation-and-training">Graph augmentation andtraining</h2><h3 id="graph-augmentation-for-gnns">Graph augmentation for GNNs</h3><p><strong>Idea</strong>: input graph != computation graph</p><p><img src="/2022/04/06/Notes-for-Stanford-229W-course/image-20211008160356576.png" alt="image-20211008160356576" style="zoom:80%;"></p><p><strong>feature augmentation</strong>: for the input graph does nothave node featur</p>]]></content>
      
      
      <categories>
          
          <category> 图神经网络 (Graph Neural Network) </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Welcome to Ten&#39;s Blog</title>
      <link href="/2022/04/06/%E9%A6%96%E9%A1%B5/"/>
      <url>/2022/04/06/%E9%A6%96%E9%A1%B5/</url>
      
        <content type="html"><![CDATA[<h1 id="欢迎来到我的博客">欢迎来到我的博客~</h1><p>大家好！我是任高鹏。我会在这个博客上传我的学习笔记。我目前的研究内容是分子表示学习以及分子生成，有以下几个感兴趣的方向：</p><ol type="1"><li>Transformer + GNN</li><li>给定蛋白质的分子生成 (Molecule generation with specific proteinbinding sites)</li><li>基于力场的分子自监督学习 (Molecular self-supervised learning basedon force field)</li><li>通过GNN或NN求解薛定谔方程 (Solve Schrödinger equation by GNN orNN)</li></ol>]]></content>
      
      
      <categories>
          
          <category> 博客 (Blog) </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>G-SphereNet笔记</title>
      <link href="/2022/04/06/GSphereNet%E7%AC%94%E8%AE%B0/"/>
      <url>/2022/04/06/GSphereNet%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h3 id="an-autoregressive-flow-model-for-3d-molecular-geometry-generation-from-scratch">AnAutoregressive Flow Model for 3D Molecular Geometry Generation fromScratch</h3><p><a href="https://openreview.net/forum?id=C03Ajc-NS5W">[Paper]</a> <a href="https://github.com/divelab/DIG">[Github]</a></p><p><a href="1.png"></a></p><span id="more"></span><ul><li><p><strong>目标</strong>：从头生成3D分子结构</p></li><li><p><strong>现有模型</strong></p><ol type="1"><li>生成2D分子</li><li>通过已有的2D分子生成3D结构</li></ol></li><li><p><strong>模型概要</strong></p><ol type="1"><li>模型一部分来自于SphereNet</li><li>序列地放置原子</li><li>分子的3D坐标隐式地通过距离、角度和二面角体现</li><li>通过SphereNet和注意力机制提取条件信息</li></ol></li><li><p><strong>相关工作</strong></p><ol type="1"><li>通过序列模型生成SMILES</li><li>通过图生成模型去得到原子类型、邻接矩阵</li><li>3D分子从头生成，这个任务可以被分为两个任务，一个是从3D分子结构中学习到一个随机生成模型使得其能够生成有效的3D分子结构；另一个是学习到一个目标分子发现模型使得量子性质分数最大化</li><li>G-SchNet使用自回归模型序列地生成新的原子，并放置到网格点上</li><li>EDMNet和3DMolNet分别通过GAN和VAE生成两个原子间的距离</li><li>E-NFs将flow模型和E(n)不变图神经网络结合，生成所有原子的one-hot坐标并且定义了在隐空间的子空间的先验概率去保证平移不变性</li></ol></li><li><p><a href="https://lilianweng.github.io/posts/2018-10-13-flow-models/"><strong>流模型</strong></a></p><ol type="1"><li>直接学习p(x)</li><li>给定一个随机变量<span class="math inline">\(z\)</span>满足<span class="math inline">\(z \sim \pi(z)\)</span>，建立一个新的随机变量<span class="math inline">\(x\)</span>，满足<span class="math inline">\(x=f(z)\)</span>其中<span class="math inline">\(f\)</span>是可逆的有，因此<span class="math inline">\(z=f^{-1}(x)\)</span>，那么目前的问题就变成了如何推断这个未知概率密度的<span class="math inline">\(x\)</span>可以看到，因为两个随机变量都满足归一化，对<span class="math inline">\(x\)</span>求导数后把<span class="math inline">\(z=f^{-1}(x)\)</span>代入，就可以得到<span class="math inline">\(p(x)\)</span>的表达式了<span class="math display">\[\begin{aligned}&amp;\int p(x) d x=\int \pi(z) d z=1 ; \text { Definition of probabilitydistribution. } \\&amp;p(x)=\pi(z) \frac{d z}{d x}=\pi\left(f^{-1}(x)\right) \frac{df^{-1}}{dx}=\pi\left(f^{-1}(x)\right)\left|\left(f^{-1}\right)^{\prime}(x)\right|\end{aligned}\]</span></li><li>Normalizing Flows：用可逆函数把已知分布的<span class="math inline">\(z_{i-1}\)</span>映射到<span class="math inline">\(z_i\)</span>，也就是上面那个式子，为了简单起见，对等式两边取<span class="math inline">\(\log\)</span>函数<span class="math display">\[\logp_{i}\left(\mathbf{z}_{i}\right)=\logp_{i-1}\left(\mathbf{z}_{i-1}\right)-\log \operatorname{det} \frac{df_{i}}{d \mathbf{z}_{i-1}}\]</span>因此第<span class="math inline">\(K\)</span>个变量的概率密度可写为：<span class="math display">\[\begin{aligned}\mathbf{x}=\mathbf{z}_{K} &amp;=f_{K} \circ f_{K-1} \circ \cdots \circf_{1}\left(\mathbf{z}_{0}\right) \\\log p(\mathbf{x})=\log \pi_{K}\left(\mathbf{z}_{K}\right) &amp;=\log\pi_{K-1}\left(\mathbf{z}_{K-1}\right)-\log \operatorname{det} \frac{df_{K}}{d \mathbf{z}_{K-1}} \\&amp;=\log \pi_{K-2}\left(\mathbf{z}_{K-2}\right)-\log\operatorname{det} \frac{d f_{K-1}}{d \mathbf{z}_{K-2}}-\log\operatorname{det} \frac{d f_{K}}{d \mathbf{z}_{K-1}} \\&amp;=\ldots \\&amp;=\log \pi_{0}\left(\mathbf{z}_{0}\right)-\sum_{i=1}^{K} \log\operatorname{det} \frac{d f_{i}}{d \mathbf{z}_{i-1}}\end{aligned}\]</span>这样就可以得到一个新的概率分布，但是需要注意的是转换函数<span class="math inline">\(f_i\)</span>应满足两个性质，一是它的可逆比较好算，二是它的雅克比行列式比较好算。NormalizingFlows的损失函数可以通过下式进行计算：<span class="math display">\[\mathcal{L}(\mathcal{D})=-\frac{1}{|\mathcal{D}|}\sum_{\mathbf{x} \in \mathcal{D}} \log p(\mathbf{x})\]</span></li><li>根据这个<span class="math inline">\(f\)</span>的选择，目前有几个模型可供选择：</li></ol><ol type="1"><li>RealNVP：使用bijection(或者叫affine couplinglayer)，这种映射关系是一对一的，也就是输入与输出是成对存在的。这个模型采用的bijection是：<span class="math display">\[\begin{aligned}\mathbf{y}_{1: d} &amp;=\mathbf{x}_{1: d} \\\mathbf{y}_{d+1: D} &amp;=\mathbf{x}_{d+1: D} \odot \exp\left(s\left(\mathbf{x}_{1: d}\right)\right)+t\left(\mathbf{x}_{1:d}\right)\end{aligned}\]</span>这里<span class="math inline">\(s(.)\)</span>和<span class="math inline">\(t(.)\)</span>分别是放大和平移函数。这个映射的雅克比行列式是一个下三角矩阵<span class="math display">\[\operatorname{det}(\mathbf{J})=\prod_{j=1}^{D-d}\exp \left(s\left(\mathbf{x}_{1: d}\right)\right)_{j}=\exp\left(\sum_{j=1}^{D-d} s\left(\mathbf{x}_{1:d}\right)_{j}\right)\]</span>因为不用计算<span class="math inline">\(s(.)\)</span>和<span class="math inline">\(t(.)\)</span>的雅克比行列式，因此他们都可以是神经网络。由于在一个仿射层中一些维度是保持不变的，因此为了让所有的输入都有机会改变，我们可以在每次应用放射层时翻转输入。对于大规模的输入，可以在仿射层中采用采样的方法，具体可见<a href="https://arxiv.org/abs/1605.08803">paper</a></li><li><a href="https://arxiv.org/abs/1807.03039">Glow</a>：拓展了ReakNVP模型，总共有三个部分，第一个部分是Activationnormalization，和BN很像，但是只在1个batch下进行计算，将每个channel的输出归一化后使用新的放大和偏置参数去训练；第二个部分是可逆的1x1卷积，它的雅克比行列式可写为<span class="math display">\[\log \operatorname{det} \frac{\partial\operatorname{conv} 2 \mathrm{~d}(\mathbf{h} ; \mathbf{W})}{\partial\mathbf{h}}=\log \left(|\operatorname{det} \mathbf{W}|^{h \cdot w}\mid\right)=h \cdot w \cdot \log |\operatorname{det}\mathbf{W}|\]</span>其中<span class="math inline">\(h\)</span>和<span class="math inline">\(w\)</span>分别是张量的高和宽，<span class="math inline">\(\mathbf{h};\mathbf{W}\)</span>分别是输入张量和参数矩阵；第三个部分就是Bijection层</li></ol><ol start="5" type="1"><li>自回归流模型：自回归是为了处理序列数据，就是在给定之前的状态预测下一时刻的状态，即<span class="math inline">\(p(x_i|x_{1:i-1})\)</span>。如果使用一个自回归模型作为flow的变换时这个模型就叫做自回归流模型，下面将先介绍几个自回归模型MADE,PixelRNN，WaveNet，然后再讲几个自回归流模型MAF和IAF</li></ol><ol type="1"><li><a href="https://arxiv.org/abs/1502.03509">MADE</a>：把Autoencoder里面的权重矩阵乘以一个binary-masked的矩阵，从而使得输出只考虑之前的信息</li><li><a href="https://arxiv.org/abs/1601.06759">PixalRNN</a>：针对图像的深度生成模型，一次产生一个像素，在生成当前像素点时，模型会看到之前生成的像素点。使用对角的BiLSTM去获取之前的Context，但是没办法并行了</li><li><a href="https://arxiv.org/abs/1705.07057">MAF</a>：生成数据的概率是已知概率分布的仿射变换</li><li><a href="https://arxiv.org/abs/1606.04934">IAF</a>：与MAF相反，使用相逆的仿射函数</li></ol></li><li><p><strong>方法</strong></p><ol type="1"><li>使用点云作为输入，也就是<span class="math inline">\(G=(A,R)\)</span>其中<span class="math inline">\(A\)</span>是原子类型矩阵，<span class="math inline">\(R\)</span>是原子坐标矩阵</li><li>将分子生成任务作为一个序列决策任务，在第<span class="math inline">\(i\)</span>个步骤，使用之前的点云信息得到隐变量，根据这个隐变量生成分子<span class="math display">\[a_{i}=g^{a}\left(z_{i}^{a} ; A_{i}, R_{i}\right),r_{i}=g^{r}\left(z_{i}^{r} ; A_{i}, R_{i}\right), \quad i \geq1\]</span></li><li>通过自回归流进行分子生成，首先需要把原子类型转为连续变量<span class="math display">\[\tilde{a}_{i}=a_{i}+u, u \sim U(0,1)^{k}, \quad i\geq 1\]</span>为了生成<span class="math inline">\(\tilde{a}_{i}\)</span>，首先从标准正态分布中取值得到一个隐变量<span class="math inline">\(z_i\)</span>，然后通过映射函数<span class="math display">\[\tilde{a}_{i}=s_{i}^{a} \odotz_{i}^{a}+t_{i}^{a}, \quad i \geq1\]</span>其中缩放因子和偏置都是根据之前生成的原子得到的条件信息</li><li>与分子类型同理，可以生成距离，角度和二面角</li><li>首先通过G-SphereNet得到每个原子更新后的表达，然后经过一个MLP分类器，如果分类的分数比0.5大，那就放在待选列表里，如果待选列表为空，表明不需要生成分子了，否则应随机地从待选列表里选择一个原子</li><li>作者表示如果直接进行atom-wiseFFNN的话生成的新原子的位置不靠谱，因此使用了多头自注意力机制使focalatom可以得到其他原子的信息</li><li>特别地，对于空间的上下文信息，作者将其与原子类型的embedding相乘</li></ol></li><li><p><strong>训练</strong></p><ol type="1"><li>使用Prim算法使得采样的focal atom总是离最新的原子最近</li><li>损失函数如下：<span class="math display">\[\begin{aligned}\log p(G) &amp;=\sum_{i=1}^{n-1}\left[\logp_{Z_{a}}\left(z_{i}^{a}\right)+\log \left|\frac{\partial\tilde{a}_{i}}{\partialz_{i}^{a}}\right|\right]+\sum_{i=1}^{n-1}\left[\logp_{Z_{d}}\left(z_{i}^{d}\right)+\log \left|\frac{\partiald_{i}}{\partial z_{i}^{d}}\right|\right] \\&amp;+\sum_{i=2}^{n-1}\left[\logp_{Z_{\theta}}\left(z_{i}^{\theta}\right)+\log \left|\frac{\partial\theta_{i}}{\partialz_{i}^{\theta}}\right|\right]+\sum_{i=3}^{n-1}\left[\logp_{Z_{\varphi}}\left(z_{i}^{\varphi}\right)+\log \left|\frac{\partial\varphi_{i}}{\partial z_{i}^{\varphi}}\right|\right]\end{aligned}\]</span>其中<span class="math inline">\(z_i\)</span>可以通过映射的反函数求得</li></ol></li><li><p><strong>实验</strong></p><ol type="1"><li>随机3D分子几何生成，使用QM9数据集。3D分子几何通过<a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/bkcs.10334">Kim</a>提出的方法变为3D分子，使用有效性作为评价指标，有效性是指所有不违反化学价规则的分子占所有生成分子的比例。通过键长分布的MMD距离，把距离与常见的化学键距离做比较，从而确定生成的到底是什么键(好麻烦，不如直接用化学键生成)，有效性才88%</li><li>目标分子发现，用了两个任务，一个是最小化HOMO-LUMOgap，另一个是最大化各向异构极化性。将QM9里面小的HOMO-LUMO和大的各向异构极化性的分子拿出来，然后去做分子生成。评价的指标是看生成的分子中比QM9里最小的HOMO-LUMO以及最大的各向异构极化性分子还大的分子的比例</li><li>消融实验：local feature &lt; global feature；without 3D information&lt; with 3D information；focal atom从50%里面选择 &gt;直接采用softmax后最大比例的分子</li></ol></li><li><p><strong>Limitations</strong></p><ol type="1"><li>原子类型有没有都考虑</li><li>化学键的选择对于生成的位置坐标的精度要求有点高</li><li>由点云-&gt;分子图的方法是否合理</li><li>反向设计是否不太现实</li></ol></li><li><p><strong>Development</strong></p><ol type="1"><li>不要用点云，保留键的信息，从而避免从点云-&gt;分子图这个过程</li><li>反向设计可以使用动态规划、强化学习等序贯决策过程进行设计</li><li>需要考虑多个原子类型</li><li>综上所述，context encoder应满足几个条件</li></ol><ol type="1"><li>能够处理不同原子类型</li><li>使用角度、距离、二面角生成分子</li><li>不使用点云而使用分子结构</li><li>为了生成合适的键，需要考虑原子的杂化类型</li></ol></li></ul>]]></content>
      
      
      <categories>
          
          <category> 分子生成 (Molecule Generation) </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>SBDD笔记</title>
      <link href="/2022/04/06/SBDD%E7%AC%94%E8%AE%B0/"/>
      <url>/2022/04/06/SBDD%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h3 id="a-3d-generative-model-for-structure-based-drug-design">A 3DGenerative Model for Structure-Based Drug Design</h3><p><a href="https://proceedings.neurips.cc/paper/2021/hash/314450613369e0ee72d0da7f6fee773c-Abstract.html">[Paper]</a><a href="https://github.com/luost26/3D-Generative-SBDD">[Github]</a></p><p><img src="/2022/04/06/SBDD%E7%AC%94%E8%AE%B0/SBDD.png"></p><span id="more"></span><ul><li><strong>目标</strong>：生成与特定蛋白质位点结合的<em>小分子</em></li><li><strong>已有模型</strong>：<ol type="1"><li>基于SMILES和基于图的方法，但是这两种方法没办法考虑到空间信息(?图应该可以)</li><li>直接在3D空间生成分子，但是他们一般生成的分子比较小</li><li>立体像素化的模型，但采样的质量受限于立体像素</li></ol></li><li><strong>SBDD模型概要</strong>：<ol type="1"><li>将目标变为对分子在3D空间出现的概率分布进行建模，即<span class="math inline">\(p(e, \boldsymbol{r} \mid\mathcal{C})\)</span>，其中<span class="math inline">\(\mathcal{C}\)</span>是输入的结合位点，<span class="math inline">\(\boldsymbol{r}\)</span>是原子的空间坐标，<span class="math inline">\(e\)</span>是原子类型</li><li>建立了一个网络，给定空间坐标，在给定结合位点的情况下预测原子类型的概率</li><li>为了让结合位点具有旋转不变性，使用了图神经网络</li><li>上述模型有两个缺点：在生成空间上原子的概率后由于每个原子与其他原子不相连，因此暂且不是一个有效的分子；期望的采样方法应该能够生成多样的分子集</li><li>为了解决上面的缺点，作者提出了自回归采样算法，这个算法就是每次在上面那个概率分布下采样一个原子，把它加入到context(可以理解为已有信息)中，直到没有空间容纳新的原子，这种采样方法与VAE和GAN相比避免使用了隐变量，减少了模型复杂度</li></ol></li><li><strong>相关工作</strong>：<ol type="1"><li>基于字符串的模型，比如用RNN对SMILES进行建模，然而这个这种表示无法捕捉分子的相似度</li><li>基于图的模型，比如VAE，强化学习等是通过自回归的方式来序列地增加原子</li><li>直接在3D空间生成分子的模型，比如用部分生成好的分子作为输入，然后预测下一个原子的种类和与之前原子的位置；也有用强化学习把分子生成作为一个时序任务，这个模型以原子的势能函数作为奖励函数，能够生成真实的3D分子，但是对相对而言大一些的分子不太有效(?可以查来看看)</li><li>把三维分子放在网格中的方法，这样子任务就编程了图像生成方法，因此可以使用VAE、GAN等方法去生成分子图像，这个方法得到的分子可以很大，然而生成分子的质量受限于分辨率的大小是得不到保证的</li></ol></li><li><strong>方法</strong><ol type="1"><li>结合位点可以用一系列原子来表示<span class="math inline">\(\mathcal{C}=\left\{\left(\boldsymbol{a}_{i},\boldsymbol{r}_{i}\right)\right\}_{i=1}^{N_{b}}\)</span>其中<span class="math inline">\(N_b\)</span>表示原子数目，<span class="math inline">\(\boldsymbol{a}_{i}\)</span>表示第<span class="math inline">\(i\)</span>个原子的特征</li><li>如上所述，模型要学习的目标是给定结合位点和原子位置，给出这个位置属于哪种原子的问题，这个问题本质上是一个分类问题，即预测在这些不同类别的原子的概率</li><li>模型由两部分组成，一个是ContextEncoder，其实就是得到结合位点中每一个原子的表示；另一个是SpatialClassifier，把坐标信息作为输入，然后聚合靠近这个原子的信息，并预测该原子的类型</li><li>Context Encoder：用的就是SchNet</li><li>SpatialClassifier：聚集周围原子的信息，然后经过一个MLP预测得到未经归一化的概率，最后每个元素的概率等于类似SoftMax的一个函数，区别是在分母加了一个1，用于表示不放元素的概率(=exp(0))</li><li>现在已经有概率云了，需要从概率云中进行采样，来得到分子。首先得到联合概率分布，<span class="math display">\[p(e, \boldsymbol{r} \mid\mathcal{C})=\frac{\exp (\boldsymbol{c}[e])}{Z}\]</span> 其中<span class="math inline">\(Z\)</span>是一个归一化参数，<span class="math inline">\(c\)</span>是上面进行spaitalclassifier时最后的MLP。(注：作者可能就没有用到这里的<span class="math inline">\(Z\)</span>)，采样的流程如下：在t时刻，Context包括已经被选中的t个原子；在t+1时刻，根据原子种类和位置的联合概率分布在已知Context的条件下(公式是上面那个吗?t时刻的Context如何体现?)，抽样得到t+1时刻的原子种类和位置。</li><li>最后还需要一个分类器用于判断是否已经走到头了</li></ol></li><li><strong>训练</strong><ol type="1"><li>使用了完形填空式的训练方法，也就是在训练过程中遮盖掉一些原子，然后让神经网络去预测这部分</li><li>采用BCELoss来判断原子是否在正确的位置上，采用标准列表式交叉熵损失判断元素的种类，采用BCE在最后的Frontier分类器上</li></ol></li><li><strong>实验</strong><ol type="1"><li>用了两个任务，一个是分子设计，也就是给定结合位点去生成分子；第二个是连接预测，也就是生成子结构去连接在结合位点的两个片段</li><li>数据集使用的是<em>CrossDocked</em>数据集，做了一些预处理，比如把RMSD大于1埃的数据点去掉，采用<em>mmseqs2</em>取得有30%的蛋白质序列相同的数据点，最后就留下100000蛋白质-配体对用于训练，100个蛋白质用于测试</li><li>采用的评价指标有，亲和力、Vina分数、药物可能性、合成性；又定义了两个新的指标，一个是高结合力样本的概率以及多样性</li></ol></li><li><strong>Limitations</strong><ol type="1"><li>原子类型太少了</li><li>模型每次都要把蛋白质计算一遍，计算量太大了</li></ol></li></ul>]]></content>
      
      
      <categories>
          
          <category> 分子生成 (Molecule Generation) </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>MoCo笔记</title>
      <link href="/2022/03/30/MoCo/"/>
      <url>/2022/03/30/MoCo/</url>
      
        <content type="html"><![CDATA[<h2 id="momentum-contrast-for-unsupervised-visual-representation-learning">MomentumContrast for Unsupervised Visual Representation Learning</h2><p><a href="https://openaccess.thecvf.com/content_CVPR_2020/html/He_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_CVPR_2020_paper.html">paper</a><a href="https://github.com/facebookresearch/moco">code</a></p><p><img src="/2022/03/30/MoCo/MOCO.png" title="模型总览与zero-shot推理"></p><hr><span id="more"></span><h3 id="什么是对比学习">什么是对比学习</h3><ol type="1"><li>通过相似度来进行无监督学习</li><li>通过代理任务来得到两个图片是否相似，如instancediscrimination：将一张图片进行随机裁剪和数据增强得到两个处理后的图片，将这两张图片认为是正样本，其他图片对这两张图片而言是负样本</li><li>对比学习在找完正负样本后所做的就是抽取特征，接着使用常见的损失函数如NCE反向传播</li><li>关键在于找到定义正样本和负样本的规则(代理任务, pretext tasks)</li></ol><h3 id="介绍">介绍</h3><ol type="1"><li>无监督模型在NLP上的表现很好，如GPT，BERT</li><li>对比学习可以被当做动态字典查询问题，即对于目标图片特征(anchor/key)寻找与最相似的图片特征(positive-negative/value)</li><li>动态字典越大越好-能够更好地在高维空间进行采样</li><li>字典中的keys应该用相同或相似的编码器得到</li><li>受限于显存，用队列表示keys，即得到mini-batch样本的特征后，将其放入队列，然后把最早的mini-batch的特征移出队列</li><li>使用队列的话字典里的特征就不一致了，因为一部分来自老的，一部分来自新的，采用动量的编码器解决这个问题，即参数一部分来query的编码器，一部分来自前一步的参数，通过调整两者的比例，也就是使参数更多地来自前一步的参数，那么参数将会更新地非常缓慢，从而缓解了队列特征不一致的问题</li><li>代理任务选择的是instance discrimination方法</li><li>最后MoCo可以在中型数据集ImageNet或者大型数据集Instagramimage得到非常好的效果</li></ol><h3 id="讨论和结论">讨论和结论</h3><ol type="1"><li>数据集的增大对于效果的提升没有很多，可能是代理任务的问题</li><li>有没有可能把MoCo和NLP里的masked auto-encoding结合起来(kaiming大神-MAE)</li></ol><h3 id="方法">方法</h3><ol type="1"><li>noise contrasive estimation(NCE)，能够解决softmax类别过多而无法过大的问题。NCE将多分类问题当作一个二分类问题，一共有两类，一类是datasample，另一类是noisy contrastive。</li><li>InfoNCE <span class="math display">\[\mathcal{L}_{q}=-\log\frac{\exp \left(q \cdot k_{+} / \tau\right)}{\sum_{i=0}^{K} \exp\left(q \cdot k_{i} / \tau\right)}\]</span> where <span class="math inline">\(\tau\)</span>是一个温度超参数，也就是控制分布的形状，<span class="math inline">\(K\)</span>指的是负样本的数量</li><li>动量对比<ul><li>使用队列能够使字典大小和batch size分离开，从而使用标准的batchsize。</li><li>使用队列能够使字典使用之前编码好的key，而不用重新进行计算</li><li>字典是整个数据集的一个子集，对应了前面提到的NCE中的estimation，即只选用一部分样本作为负例，从而减小计算开销</li><li>使用队列可以移走最老的特征，从而保持了字典的一致性，即几乎都是用一个编码器编的</li><li>因为这个队列非常大，因此很难去通过反向传播去更新所有key的编码器</li><li>能不能直接吧query的编码器直接给key用呢？结果并不好，可能是因为编码器太快改变了，因此使得队列中元素的一致性遭到破坏。由此引出动量更新：<span class="math inline">\(\theta_{\mathrm{k}} \leftarrow m\theta_{\mathrm{k}}+(1-m) \theta_{\mathrm{q}}\)</span></li><li>用一个非常大的动量(0.999)就可以使得参数更新得很慢</li><li>端到端的对比学习，也就是key和query的编码器使用同一个，并使用梯度回传更新参数。优点是字典的一致性非常高，缺点就是字典的大小需要和mini-batch的size一样，从而限制了字典的大小</li><li>memory bank。对于query使用编码器，对于key建立一个memorybank，这个bank是将所有的key储存起来，接着在训练的时候抽样一些算出来contrastiveloss后更新query的编码器，接着用这个编码器将抽样后的样本重新计算特征，将计算完的特征再扔回memorybank里。这样会使得key的特征的一致性非常差。同时不太容易处理数据集非常大的任务</li></ul></li></ol><p>P.S. trivial solution - 捷径解 (TSTiNet)</p><ol start="4" type="1"><li>伪代码</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"># f_q, f_k: encoder networks for query and key</span><br><span class="line"># queue: dictionary as a queue of K keys (CxK)</span><br><span class="line"># m: momentum</span><br><span class="line"># t: temperature</span><br><span class="line"></span><br><span class="line">f_k.param = f_q.params # initialize</span><br><span class="line">for x in loader: # load a minibatch x with N samples</span><br><span class="line">x_q = aug(x) # a randomly augmented version</span><br><span class="line">x_k = aug(x) # another randomly augmented version</span><br><span class="line"></span><br><span class="line">q = f_q.forward(x_q)  # queries: NxC</span><br><span class="line">k = f_k.forward(x_k)  # keys: NxC</span><br><span class="line">k = k.detach() # k进行梯度回传操作</span><br><span class="line"></span><br><span class="line"># positive logits: Nx1</span><br><span class="line">l_pos = bmm(q.view(N, 1, C), k.view(N, C, 1))</span><br><span class="line"></span><br><span class="line"># negative logits: NxK</span><br><span class="line">l_neg = mm(q.view(N, C), queue.view(C, K))</span><br><span class="line"></span><br><span class="line"># logits: Nx(1+K)</span><br><span class="line">logits = cat([l_pos, l_neg], dim=1)</span><br><span class="line"></span><br><span class="line"># contrastive loss</span><br><span class="line">labels = zeros(N) # positives are the 0-th</span><br><span class="line">loss = CrossEntropyLoss(logits/t, labels)</span><br><span class="line"></span><br><span class="line"># query网络的更新</span><br><span class="line">loss.backward()</span><br><span class="line">update(f_q.params)</span><br><span class="line"></span><br><span class="line"># momentum update: key network</span><br><span class="line">f_k.params = m*f_k.params + (1-m)*f_q.params</span><br><span class="line"></span><br><span class="line"># 更新字典</span><br><span class="line">enqueue(queue, k) # 让minibatch进入队列</span><br><span class="line">dequeue(queue) # 让minibatch走出队列</span><br></pre></td></tr></table></figure><ol start="5" type="1"><li>Shuffle BN: 为了防止模型学到捷径，因为BN会算当前样本的runningmean和runningvariance，从而泄露信息，那么模型就会根据这些泄露的信息很容易找到那个正样本。因此ShuffleBN采用先把样本的顺序打乱，送到各个GPU上，最后再恢复顺序</li></ol><h3 id="实验与结果">实验与结果</h3><ol type="1"><li>在ImageNet-1k和Instegram-1B进行训练</li><li>学习率设为了30，可能有监督对比学习和无监督对比学习学到的特征非常不一致</li><li>MoCo的扩展性好，硬件要求低</li><li>无监督学习最主要的目标最重要的就是生成可泛化的特征</li><li>用了特征归一化，然后用有监督训练的超参数做微调</li></ol>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 (Computer Vision) </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>CLIP笔记</title>
      <link href="/2022/03/30/CLIP/"/>
      <url>/2022/03/30/CLIP/</url>
      
        <content type="html"><![CDATA[<h2 id="learning-transferable-visual-models-from-natural-language-supervision">LearningTransferable Visual Models From Natural Language Supervision</h2><p><a href="https://arxiv.org/abs/2103.00020">paper</a> <a href="https://github.com/OpenAI/CLIP">Github</a></p><p><img src="/2022/03/30/CLIP/CLIP.png"></p><hr><span id="more"></span><h3 id="关键点">关键点</h3><ol type="1"><li>结合自然文本和图片生成数据集</li><li>无需人工标注</li><li>对比学习</li><li>多模态工作</li><li>标签不是提前定义好的列表式的标签</li></ol><h3 id="综述">综述</h3><ol type="1"><li>之前通过自然语言协助图片分类的工作有着最大的问题就是规模不够大</li><li>之前的工作多是用文本带来的弱监督信号去帮助图片的有监督学习，但是这类任务仍然针对的是固定类别的类，没有zero-shot的能力</li></ol><h3 id="方法">方法</h3><p><font color="red" size="4">概述</font></p><ol type="1"><li>核心是用自然语言的有监督讯号训练视觉任务</li><li>Transformer和BERT的兴起使得自然语言模型更加强大</li><li>数据集有4个亿的图片单词数据对</li><li>训练效率对多模态工作的结果非常重要</li><li>预测学习（给定图片预测文本）与对比学习相比需要巨大的计算资源</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># image_encoder - ResNet or Vision Transformer</span><br><span class="line"># text_encoder - CBOW or Text Transformer</span><br><span class="line"># I[n, h, w, c] - minibatch of aligned images</span><br><span class="line"># T[n, l] - minibatch of aligned texts</span><br><span class="line"># W_i[d_i, d_e] - 将图片特征投影到多模态的空间</span><br><span class="line"># W_t[d_t, d_e] - 将文本特征投影到多模态的空间</span><br><span class="line"># t - 学得的温度参数 ???</span><br><span class="line"></span><br><span class="line"># 抽取特征</span><br><span class="line">I_f = image_encoder(I) # [n, d_i]</span><br><span class="line">T_f = text_encoder(T) # [n, d_t]</span><br><span class="line"></span><br><span class="line"># 使模型能够学习到多模态的特征</span><br><span class="line">I_e = l2_normalize(np.dot(I_f, W_i), axis=1)</span><br><span class="line">T_e = l2_normalize(np.dot(T_f, W_t), axis=1)</span><br><span class="line"></span><br><span class="line"># 算下相似度</span><br><span class="line">logits = np.dot(I_e, T_e) * np.exp(t)</span><br><span class="line"></span><br><span class="line"># 生成真值并计算损失</span><br><span class="line">labels = np.arange(n) # 因为都是在对角线上配的的</span><br><span class="line">loss_i = cross_entropy_loss(logits, labels, axis=0)</span><br><span class="line">loss_t = cross_entropy_loss(logits, labels, axis=1)</span><br><span class="line">loss = (loss_i + loss_t) / 2</span><br></pre></td></tr></table></figure><ol start="6" type="1"><li>在这个工作中，最后用的是线性投射层，而没有使用非线性透射层</li></ol><p><font color="red" size="4">训练</font></p><ol type="1"><li>调参都是用小模型训练一个周期的结果来调的</li><li>batch_size = 32768</li><li>混精度训练 (???)</li><li>GPU并行计算</li></ol><p><a href="https://lilianweng.github.io/posts/2021-09-25-train-large/">大模型训练技巧</a></p><ol start="5" type="1"><li>训练ViT比训练残差网络效率更高</li><li>最后又在更大的图片上微调了一下</li></ol><h3 id="实验">实验</h3><ol type="1"><li>如何作zero-shot推理?</li></ol><p>A: 图片通过编码器得到一个特征，感兴趣的类别输入到"A photo of a{object}"中，然后经过一个文本编码器，得到n个特征，将这n个特征和图片特征点乘后作Softmax，得到在每个类别的概率。P.S.为什么不直接用这个类别这一个单词呢？因为训练就是用的句子，存在distributiongap。</p><ol start="2" type="1"><li>Prompt (提示) engineering and ensembling ???</li></ol><ul><li>语言歧义性的问题，比如boxer可以是一种狗也可以是拳击运动员。使用"Aphoto of a{object}"则使得object一定是名词，因此一定程度上缓解了语言歧义性的问题。</li><li>另外在宠物的数据集加上一句"a type ofpet"作为提示也会得到更好的效果</li><li>对prompt进行ensemble，即使用很多prompt，最后的结果取他们的平均，则会得到更好的效果。本文用了80个提示模板P.S. Linear probe指冻住主干网络，只微调最后一个全连接层的操作</li></ul><ol start="3" type="1"><li>用全部数据和之前的特征学习方法进行对比</li></ol><ul><li>仍然使用linearprobe而不采用fine-tune，因为fine-tune要训练整个网络，这样就不能分辨预训练模型的好坏了；另外也不用调参。</li><li>模型非常好</li></ul><h3 id="limitation">Limitation</h3><ol type="1"><li>和各个数据集的SOTA结果还是有一定差距的，扩大规模不太现实</li><li>在有些数据集上表现不太好，无法处理抽象的概念（比如数物体或者判断异常）</li><li>在MNIST这类数据集上不太好，和自然图像还是有点差距的，是一个out-of-distribution的数据集</li><li>只是从给定类别去做推理，而不能直接写出图片的标签</li><li>对数据的利用不是很高效，可以用数据增强、伪标签或自监督减小数据用量</li><li>数据没有经过清洗，很可能会带一些社会偏见</li><li>很多任务用语言都无法描述的</li><li>如何在few-shot也能具有更好的效果</li></ol><center><font color="brown" size="5"> 打破了固定标签类别的范式 </font></center>]]></content>
      
      
      <categories>
          
          <category> 计算机视觉 (Computer Vision) </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>机器学习与量子物理</title>
      <link href="/2022/03/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E9%87%8F%E5%AD%90%E7%89%A9%E7%90%86/"/>
      <url>/2022/03/29/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E9%87%8F%E5%AD%90%E7%89%A9%E7%90%86/</url>
      
        <content type="html"><![CDATA[<p><a href="https://link.springer.com/book/10.1007/978-3-030-40245-7">[SOURCE]</a></p><p>介绍机器学习在量子物理(主要是量子化学)中的应用，如分子性质预测等</p><span id="more"></span><h2 id="introduction">Introduction</h2><h3 id="结构-性质关系">结构-性质关系</h3><ul><li>分子的反向设计通常难于正向预测</li><li><em>水蒸气</em>的性质可以只取决于单个水分子(即两个O-H距离和一个H-O-H角度)，这些空间信息以极窄的分布存在；至于<em>液态水</em>，事实上单个水分子的状态仍没有什么变化，引起液态水和水蒸气性质差异的是分子间相互作用；至于<em>冰</em>，水分子内的自由度仍然没有改变，水分子间的自由度发生了变化，他们不像在气相或液相那样可以随意移动。冰是一种晶体，这意味着每个水分子以一定的周期形式排列着，单个晶体有时会对其性质产生影响。</li><li>至于其他的无定型固体，如蛋白质，它是由氨基酸序列折叠而来的，我们可以通过把蛋白质放到溶液中去结晶化，从而获得更加精确的分子结构。</li><li>分子中的自由度可以分为强自由度和弱自由度，弱自由度具有较大的方差(如分子间相互作用)，这种自由度可以不作为分子结构的构成；强自由度有着窄的概率分布(低方差)，且他们的平均值组成了分子。</li><li>通常我们考虑的结构-性质关系不考虑弱自由度。</li><li>一般针对正向问题和反向问题，我们的目标都是去求概率分布，而非一个确定的函数。</li><li>分子性质可以分为两类，电子性质和热力学性质，电子性质通常是由电子云分布决定的，热力学性质是由弱自由度(也就是原子核的移动)统计得到的。热力学性质可以分为平衡性质与不平衡性质，平衡性质比如说沸点、溶点等，非平衡性质指化学反应或者物质传递等。</li></ul><h3 id="量子力学">量子力学</h3><ul><li>希尔伯特空间(Hilbert Space)<ol type="1"><li>是一个线性向量空间</li><li>向量间的内积满足如下性质<ol type="a"><li>共轭对称，即一对向量和他们交换后的复共轭向量是相等的 <span class="math inline">\(\langle y, x\rangle=\overline{\langle x,y\rangle}\)</span></li><li>线性的 <span class="math inline">\(\left\langle a x_{1}+b x_{2},y\right\rangle=a\left\langle x_{1}, y\right\rangle+b\left\langle x_{2},y\right\rangle\)</span></li><li>正定的 <span class="math inline">\(\left\langlex,x\right\rangle=|x|^2\ge 0\)</span></li><li>共轭线性的 <span class="math inline">\(\left\langle x, a y_{1}+by_{2}\right\rangle=\bar{a}\left\langle x,y_{1}\right\rangle+\bar{b}\left\langle x,y_{2}\right\rangle\)</span></li><li>两点之间的距离定义为 <span class="math inline">\(d(x,y)=\|x-y\|=\sqrt{\langle x-y,x-y\rangle}\)</span></li></ol></li><li>该空间是可分离的，包含一个可数的、稠密的子集</li><li>是完备的（没有间隔）</li></ol></li><li>在希尔伯特空间表示一个物体的状态通过下式：<span class="math display">\[\begin{equation}|\psi\rangle:=\int \operatorname{d\mathbf{r}}\psi(\mathbf{r})|\mathbf{r}\rangle\end{equation}\]</span></li><li>与特征值和特征向量满足的关系类似(<span class="math inline">\(\hat{L}\left|\psi_{i}\right\rangle=\lambda_{i}\left|\psi_{i}\right\rangle\)</span>)，将其中的线性算子改为哈密顿算子(Hamiltonian)，对应的特征值变为能量E，并将状态用波函数<span class="math inline">\(\psi(\mathbf{r})\)</span>来代替： <span class="math display">\[\hat{H} \psi_{i}(\mathbf{r})=E_{i}\psi_{i}(\mathbf{r})\]</span></li><li>目前大部分的量子力学方法，如密度泛函等，最快也只能到O(<span class="math inline">\(N^3\)</span>)</li><li>哈密顿算子中取决于原子核位置的项被叫做势能面(potential energysurface)</li></ul><h3 id="统计力学">统计力学</h3><ul><li>统计力学对于弱自由度上的移动的建模非常有效，核心思想就是大部分的移动都可以合理省去，与物理性质相关的特征可以用较少的自由度来表示。</li><li>统计力学最主要的结果就是：对于一个材料，给定一个温度，那么他的微观态的概率密度分布与玻尔兹曼因子成比例<span class="math display">\[P(\mathbf{s}) \propto\mathrm{e}^{-\frac{V(\mathbf{s})}{T}}\]</span></li><li>归一化的概率分布为： <span class="math display">\[Z(T)=\int\mathrm{ds} \mathrm{}^{\frac{-E(\mathrm{~s})}{T}}, \quadP(\mathrm{~s})=\frac{1}{Z(T)}\mathrm{e}^{-\frac{E(\mathrm{~s})}{T}}\]</span></li><li>然后平均能量就可以写为： <span class="math display">\[\langleE\rangle=\int \mathrm{ds} P(\mathrm{~s}) E(\mathrm{~s})=T^{2}\frac{\partial \ln Z}{\partial T}\]</span></li><li>统计力学的计算复杂度主要就集中于上面的积分过程，对于具有较多原子的材料也有着计算复杂度高的问题。但是这通常可以通过蒙特卡洛模拟来减少计算量，也就是选取一些代表性的sample，计算他们的概率。因此统计力学的任务就变成了得到一些统计意义上重要的微观状态(也就是有着大的玻尔兹曼因子的微观状态)。</li><li>最常用的得到这种微观状态的方法就是分子动力学，这种方法让原子受到势能面的影响而进行经典力学上的移动，然后我们可以通过截取原子们运动的快照来获得微观状态。</li></ul><h2 id="kernel-methods-for-quantum-chemistry">Kernel Methods for QuantumChemistry</h2><p>To be continued ...</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 (Machine Learning) </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>搭建个人博客</title>
      <link href="/2022/03/29/%E5%88%9B%E5%BB%BA%E5%8D%9A%E5%AE%A2/"/>
      <url>/2022/03/29/%E5%88%9B%E5%BB%BA%E5%8D%9A%E5%AE%A2/</url>
      
        <content type="html"><![CDATA[<p>这是个人博客搭建的向导</p><span id="more"></span><h3 id="相关工具下载">相关工具下载</h3><ul><li><a href="https://nodejs.org/en/">Node.js</a>：使用<code>node -v</code>和<code>npm -v</code>查看是否安装成功</li><li><a href="https://git-scm.com/download/win">git</a>：使用<code>git --version</code>查看是否安装成功</li><li>Hexo：<code>npm install -g hexo-cli</code></li></ul><h3 id="github仓库搭建">Github仓库搭建</h3><ul><li>新建一个仓库，仓库名为<code>&lt;Github用户名&gt;.github.io</code></li><li>连接本地与Github服务器：<ol type="1"><li>打开Gitbash输入<code>ssh-keygen -t rsa -C "&lt;Github注册邮箱地址&gt;"</code></li><li>在<code>C:/users/&lt;用户名&gt;/.ssh</code>文件夹下，复制<em>id_rsa.pub</em>文件中的内容</li><li>拷贝内容至Github的settings中</li></ol></li></ul><p>注：在.ssh新建文件config，在里面填入</p><figure class="highlight plaintext"><figcaption><span>github.com</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">User 注册github的邮箱</span><br><span class="line">Hostname ssh.github.com</span><br><span class="line">PreferredAuthentications publickey</span><br><span class="line">IdentityFile ~/.ssh/id_rsa</span><br><span class="line">Port 443</span><br></pre></td></tr></table></figure><h3 id="搭建个人博客">搭建个人博客</h3><ul><li><code>hexo init</code> 初始化本地博客文件夹，注意该文件夹应为空</li><li><code>hexo g</code> 生成网页</li><li><code>hexo s</code>把生成的网页放在本地服务器，输入[http://localhost:4000/]查看效果</li><li><code>ctrl + c</code> 结束本地网页</li></ul><h3 id="更改主题-next">更改主题 (NexT)</h3><ul><li>在本地博客文件夹下载next：<code>git clone https://github.com/theme-next/hexo-theme-next themes/next</code></li><li>更改Hexo的config中的scheme值为next</li><li>修改头像：在next/_config.yml中找到<code>avatar</code></li><li>添加搜索：在next/_config.yml中找到<code>local search</code>，并根据上面网页下载搜索插件</li><li>添加分类：在next/_config.yml中找到<code>menu</code>，取消掉相关注释，然后<code>hexo new page &lt;&gt;</code></li></ul><h3 id="其他操作">其他操作</h3><ul><li><p>删除文件：删除本地文件后键入<code>hexo clean</code></p></li><li><p>将当前博客上传到github上</p><ol type="1"><li>安装部署工具：<code>npm install hexo-deployer-git --save</code></li><li>修改hexo的_config.yml文件中的deploy部分</li><li>使用<code>hexo clean</code>、<code>hexo g</code>、<code>hexo d</code></li></ol></li></ul>]]></content>
      
      
      <categories>
          
          <category> 博客 (Blog) </category>
          
      </categories>
      
      
    </entry>
    
    
  
  
</search>
